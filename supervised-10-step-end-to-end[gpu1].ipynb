{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MAIN_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f862867f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "\n",
    "from action_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536ae7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_mols = pickle.load(open(\"datasets/my_uspto/unique_start_mols.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "322bdda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101213it [01:26, 1163.44it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101213, 10)\n",
      "(101213, 10)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "main_df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "N = 100000\n",
    "np.random.seed(42)\n",
    "steps = 6\n",
    "\n",
    "def generate_train_data(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    index = []\n",
    "    \n",
    "    # Get sequences\n",
    "    try:\n",
    "        for i in range(steps):\n",
    "            actions = get_applicable_actions(mol)\n",
    "            if actions.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            # Apply a random action\n",
    "            rand_idx = np.random.randint(0, actions.shape[0])\n",
    "            product = apply_action(mol, *actions.iloc[rand_idx])\n",
    "\n",
    "            # Add it to df\n",
    "            df.loc[df.shape[0], :] = [Chem.MolToSmiles(mol)] + actions.iloc[rand_idx].tolist() + [Chem.MolToSmiles(product)]\n",
    "            index.append(actions.iloc[rand_idx].name)\n",
    "\n",
    "            # Next reactant = product\n",
    "            mol = product\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    \n",
    "    # Fix index\n",
    "    df.index = index\n",
    "    \n",
    "    # Make combinations for multi-step possibilities of source-->target\n",
    "    for i in range(df.shape[0]-1, 0, -1):\n",
    "        new_df = df.iloc[:i].copy()\n",
    "        new_df[\"product\"] = df.iloc[i][\"product\"]\n",
    "        df = pd.concat([df, new_df])\n",
    "        \n",
    "    return df\n",
    "\n",
    "df_list = []\n",
    "final_shape = 0\n",
    "# Create dataset for 5 step pred\n",
    "with Pool(30) as p, tqdm.tqdm(total=N) as pbar:\n",
    "    while final_shape < N:\n",
    "        smiles = np.random.choice(start_mols, size=(1000,))\n",
    "\n",
    "        for new_df in p.imap_unordered(generate_train_data, smiles, chunksize=10):\n",
    "            df_list.append(new_df)\n",
    "            final_shape += new_df.shape[0]\n",
    "            \n",
    "        pbar.update(final_shape - pbar.n)\n",
    "\n",
    "# randomize\n",
    "main_df = pd.concat(df_list)\n",
    "del df_list\n",
    "print(main_df.shape)\n",
    "\n",
    "main_df = pd.concat([main_df[:int(main_df.shape[0]*0.8)].sample(frac=1), main_df[int(main_df.shape[0]*0.8):].sample(frac=1)])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58b5a",
   "metadata": {},
   "source": [
    "# Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3e1a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f88d9c4b510>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3432cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48289f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 24024.2266\n",
      "Epoch 2, Loss: 11644.5195\n",
      "Epoch 3, Loss: 3179.7080\n",
      "Epoch 4, Loss: 950.4078\n",
      "Epoch 5, Loss: 723.5219\n",
      "Epoch 6, Loss: 722.2169\n",
      "Epoch 7, Loss: 706.3540\n",
      "Epoch 8, Loss: 682.1254\n",
      "Epoch 9, Loss: 665.4435\n",
      "Epoch 10, Loss: 655.7354\n",
      "\n",
      "FINAL TEST LOSS: 86.86898803710938\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.89 s, sys: 902 ms, total: 7.79 s\n",
      "Wall time: 4.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (4): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (last_layer): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden=1, hidden_size=50):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(num_hidden):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            \n",
    "        self.last_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        out = self.last_layer(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "def train(X, Y, num_hidden=1, hidden_size=50, lr=1e-2, bs=64, epochs=100):\n",
    "    train_X = torch.Tensor(X[:int(X.shape[0]*0.8)]).to(device)\n",
    "    train_Y = torch.Tensor(Y[:int(Y.shape[0]*0.8)]).to(device)\n",
    "\n",
    "    test_X = torch.Tensor(X[int(X.shape[0]*0.8):]).to(device)\n",
    "    test_Y = torch.Tensor(Y[int(Y.shape[0]*0.8):]).to(device)\n",
    "    \n",
    "    model = NeuralNet(train_X.shape[1], train_Y.shape[1], num_hidden=num_hidden, hidden_size=hidden_size).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "\n",
    "    loss_list = []\n",
    "    test_loss = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, train_X.shape[0], batch_size):\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(train_X[i:i+batch_size])\n",
    "            loss = criterion(outputs, train_Y[i:i+batch_size])\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        print ('Epoch {}, Loss: {:.4f}'.format(epoch+1, loss.item()))\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss.append(criterion(model(test_X), test_Y).item()) \n",
    "    print(\"\\nFINAL TEST LOSS:\", test_loss[-1])\n",
    "        \n",
    "    plt.plot(loss_list[5:], label=\"training loss\")\n",
    "    plt.plot(test_loss[5:], label=\"test loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "from sklearn.datasets import make_regression\n",
    "x, y = make_regression(n_samples=5000, n_features=20, noise=2, random_state=42)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "%time train(x, y, num_hidden=2, hidden_size=20, lr=1e-2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662cf55",
   "metadata": {},
   "source": [
    "# Embedding type 2 - GIN training using attribute masking on clintox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835d1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchdrug import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32366ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"models/zinc2m_gin.pth\"\n",
    "gin_model = torch.load(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cda6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_from_smile(smile):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "    return mol\n",
    "\n",
    "def get_mol_embedding(model, smiles):\n",
    "    # deepchem - attribute masking\n",
    "    if isinstance(smiles, str):\n",
    "        mol = molecule_from_smile(smiles)\n",
    "    else:\n",
    "        mol = list(map(molecule_from_smile, smiles))\n",
    "        mol = data.Molecule.pack(mol)\n",
    "    mol = mol.to(device)\n",
    "    emb = model(mol, mol.node_feature.float())[\"graph_feature\"]\n",
    "    return emb.detach().cpu().numpy()\n",
    "\n",
    "def get_atom_embedding(model, smiles, idx):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    return emb.detach().cpu()\n",
    "\n",
    "def get_action_embedding(model, action_df):\n",
    "    rsub, rcen, rsig, _, psub, pcen, psig, __ = [action_df[c] for c in action_df.columns]\n",
    "#     print(get_mol_embedding(model, rsub).shape)\n",
    "#     print(get_atom_embedding(model, rsig, rcen).shape)\n",
    "#     print(get_mol_embedding(model, rsig).shape)\n",
    "#     print(get_mol_embedding(model, psub).shape)\n",
    "#     print(get_atom_embedding(model, psig, pcen).shape)\n",
    "#     print(get_mol_embedding(model, psig).shape)\n",
    "    embedding = np.concatenate([\n",
    "#                         get_mol_embedding(model, rsub), \n",
    "#                         get_atom_embedding(model, rsig, rcen) / 5, \n",
    "                        get_mol_embedding(model, rsig), \n",
    "#                         get_mol_embedding(model, psub), \n",
    "#                         get_atom_embedding(model, psig, pcen) / 5, \n",
    "                        get_mol_embedding(model, psig)\n",
    "                    ], axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6003605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 396/396 [07:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101213, 256)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "X = []\n",
    "for i in tqdm.tqdm(range(0, main_df.shape[0], batch_size)):\n",
    "    reactants = main_df[\"reactant\"][i:i+batch_size]\n",
    "    products = main_df[\"product\"][i:i+batch_size]\n",
    "    X.append(np.concatenate([get_mol_embedding(gin_model, reactants), get_mol_embedding(gin_model, products)], axis=1))\n",
    "X = np.concatenate(X, axis=0)\n",
    "emb_len = X.shape[1]//2\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14ab411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 396/396 [03:59<00:00,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101213, 256)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i in tqdm.tqdm(range(0, main_df.shape[0], batch_size)):\n",
    "    Y.append(get_action_embedding(gin_model, main_df.iloc[i:i+batch_size][main_df.columns[1:-1]]))\n",
    "Y = np.concatenate(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1c369",
   "metadata": {},
   "source": [
    "### MSE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04ffae30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0783\n",
      "Epoch 2, Loss: 0.0624\n",
      "Epoch 3, Loss: 0.0530\n",
      "Epoch 4, Loss: 0.0457\n",
      "Epoch 5, Loss: 0.0392\n",
      "Epoch 6, Loss: 0.0351\n",
      "Epoch 7, Loss: 0.0308\n",
      "Epoch 8, Loss: 0.0277\n",
      "Epoch 9, Loss: 0.0258\n",
      "Epoch 10, Loss: 0.0241\n",
      "Epoch 11, Loss: 0.0224\n",
      "Epoch 12, Loss: 0.0225\n",
      "Epoch 13, Loss: 0.0208\n",
      "Epoch 14, Loss: 0.0195\n",
      "Epoch 15, Loss: 0.0189\n",
      "Epoch 16, Loss: 0.0179\n",
      "Epoch 17, Loss: 0.0178\n",
      "Epoch 18, Loss: 0.0166\n",
      "Epoch 19, Loss: 0.0167\n",
      "Epoch 20, Loss: 0.0162\n",
      "Epoch 21, Loss: 0.0151\n",
      "Epoch 22, Loss: 0.0149\n",
      "Epoch 23, Loss: 0.0141\n",
      "Epoch 24, Loss: 0.0143\n",
      "Epoch 25, Loss: 0.0140\n",
      "Epoch 26, Loss: 0.0135\n",
      "Epoch 27, Loss: 0.0129\n",
      "Epoch 28, Loss: 0.0120\n",
      "Epoch 29, Loss: 0.0126\n",
      "Epoch 30, Loss: 0.0125\n",
      "Epoch 31, Loss: 0.0129\n",
      "Epoch 32, Loss: 0.0133\n",
      "Epoch 33, Loss: 0.0145\n",
      "Epoch 34, Loss: 0.0130\n",
      "Epoch 35, Loss: 0.0119\n",
      "Epoch 36, Loss: 0.0118\n",
      "Epoch 37, Loss: 0.0118\n",
      "Epoch 38, Loss: 0.0121\n",
      "Epoch 39, Loss: 0.0108\n",
      "Epoch 40, Loss: 0.0112\n",
      "Epoch 41, Loss: 0.0142\n",
      "Epoch 42, Loss: 0.0156\n",
      "Epoch 43, Loss: 0.0129\n",
      "Epoch 44, Loss: 0.0128\n",
      "Epoch 45, Loss: 0.0122\n",
      "Epoch 46, Loss: 0.0126\n",
      "Epoch 47, Loss: 0.0122\n",
      "Epoch 48, Loss: 0.0109\n",
      "Epoch 49, Loss: 0.0109\n",
      "Epoch 50, Loss: 0.0115\n",
      "Epoch 51, Loss: 0.0104\n",
      "Epoch 52, Loss: 0.0114\n",
      "Epoch 53, Loss: 0.0105\n",
      "Epoch 54, Loss: 0.0108\n",
      "Epoch 55, Loss: 0.0101\n",
      "Epoch 56, Loss: 0.0102\n",
      "Epoch 57, Loss: 0.0089\n",
      "Epoch 58, Loss: 0.0088\n",
      "Epoch 59, Loss: 0.0086\n",
      "Epoch 60, Loss: 0.0095\n",
      "Epoch 61, Loss: 0.0093\n",
      "Epoch 62, Loss: 0.0106\n",
      "Epoch 63, Loss: 0.0103\n",
      "Epoch 64, Loss: 0.0097\n",
      "Epoch 65, Loss: 0.0095\n",
      "Epoch 66, Loss: 0.0104\n",
      "Epoch 67, Loss: 0.0092\n",
      "Epoch 68, Loss: 0.0094\n",
      "Epoch 69, Loss: 0.0091\n",
      "Epoch 70, Loss: 0.0098\n",
      "Epoch 71, Loss: 0.0095\n",
      "Epoch 72, Loss: 0.0089\n",
      "Epoch 73, Loss: 0.0088\n",
      "Epoch 74, Loss: 0.0102\n",
      "Epoch 75, Loss: 0.0088\n",
      "Epoch 76, Loss: 0.0090\n",
      "Epoch 77, Loss: 0.0091\n",
      "Epoch 78, Loss: 0.0097\n",
      "Epoch 79, Loss: 0.0096\n",
      "Epoch 80, Loss: 0.0111\n",
      "Epoch 81, Loss: 0.0098\n",
      "Epoch 82, Loss: 0.0102\n",
      "Epoch 83, Loss: 0.0083\n",
      "Epoch 84, Loss: 0.0086\n",
      "Epoch 85, Loss: 0.0084\n",
      "Epoch 86, Loss: 0.0084\n",
      "Epoch 87, Loss: 0.0077\n",
      "Epoch 88, Loss: 0.0080\n",
      "Epoch 89, Loss: 0.0073\n",
      "Epoch 90, Loss: 0.0073\n",
      "Epoch 91, Loss: 0.0069\n",
      "Epoch 92, Loss: 0.0072\n",
      "Epoch 93, Loss: 0.0070\n",
      "Epoch 94, Loss: 0.0072\n",
      "Epoch 95, Loss: 0.0071\n",
      "Epoch 96, Loss: 0.0077\n",
      "Epoch 97, Loss: 0.0073\n",
      "Epoch 98, Loss: 0.0079\n",
      "Epoch 99, Loss: 0.0077\n",
      "Epoch 100, Loss: 0.0092\n",
      "\n",
      "FINAL TEST LOSS: 0.0840127095580101\n"
     ]
    }
   ],
   "source": [
    "model = train(X, Y, hidden_size=500, num_hidden=3, lr=1e-3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57264831",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model_path = \"datasets/my_uspto/supervised_zinc_gin/10step-mse_model.pth\"\n",
    "torch.save(model, mse_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33f6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89384, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▏                                                         | 94/1397 [00:15<03:33,  6.10it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 63%|██████████████████████████████████████▍                      | 881/1397 [02:39<01:32,  5.55it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cr`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 75%|█████████████████████████████████████████████▏              | 1051/1397 [03:11<01:03,  5.49it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cd`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 84%|██████████████████████████████████████████████████▌         | 1176/1397 [03:35<00:38,  5.73it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ge`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 86%|███████████████████████████████████████████████████▊        | 1207/1397 [03:41<00:36,  5.21it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ti`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 93%|████████████████████████████████████████████████████████    | 1304/1397 [04:01<00:17,  5.21it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pt`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 99%|███████████████████████████████████████████████████████████▋| 1389/1397 [04:18<00:01,  4.89it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ru`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "100%|███████████████████████████████████████████████████████████▊| 1393/1397 [04:19<00:00,  4.79it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ta`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "100%|████████████████████████████████████████████████████████████| 1397/1397 [04:20<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89384, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "action_dataset = pd.read_csv(\"datasets/my_uspto/action_dataset-filtered.csv\", index_col=0)\n",
    "action_dataset = action_dataset.loc[action_dataset[\"action_tested\"] & action_dataset[\"action_works\"]]\n",
    "action_dataset = action_dataset[[\"rsub\", \"rcen\", \"rsig\", \"rbond\", \"psub\", \"pcen\", \"psig\", \"pbond\"]]\n",
    "print(action_dataset.shape)\n",
    "\n",
    "def get_action_dataset_embeddings(model):\n",
    "    action_embeddings = []\n",
    "    for i in tqdm.tqdm(range(0, action_dataset.shape[0], batch_size)):\n",
    "        action_embeddings.append(get_action_embedding(model, action_dataset.iloc[i:i+batch_size]))\n",
    "    action_embeddings = np.concatenate(action_embeddings)\n",
    "    return action_embeddings\n",
    "\n",
    "action_embeddings = get_action_dataset_embeddings(gin_model)\n",
    "print(action_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33fb20",
   "metadata": {},
   "source": [
    "### Back to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e39854d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 101213/101213 [03:29<00:00, 482.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "def get_emb_indices_and_correct_idx(row):\n",
    "    if isinstance(row, tuple): # For pandas iterrows\n",
    "        row = row[1]\n",
    "    \n",
    "    # Applicable indices\n",
    "    applicable_actions_df = get_applicable_actions(Chem.MolFromSmiles(row[\"reactant\"]))\n",
    "    if applicable_actions_df.shape[0] == 0:\n",
    "        # If there are no applicable actions detected (rdkit problems)\n",
    "        indices_used_for_data = np.where((action_dataset.index == row.name))[0]\n",
    "        correct_idx = 0\n",
    "    else:\n",
    "        indices_used_for_data = np.where(action_dataset.index.isin(applicable_actions_df.index))[0]\n",
    "        \n",
    "        # Correct index\n",
    "        applicable_actions_df = applicable_actions_df.loc[action_dataset.iloc[indices_used_for_data].index]\n",
    "        correct_idx = (applicable_actions_df.index == row.name).argmax()\n",
    "\n",
    "    \n",
    "    return indices_used_for_data, correct_idx\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, main_df.iterrows()), total=main_df.shape[0]):\n",
    "with Pool(20) as p:\n",
    "    for indices_used_for_data, correct_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, main_df.iterrows(), chunksize=50), total=main_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_indices.append(correct_idx)\n",
    "\n",
    "        assert correct_indices[-1] < len(action_embedding_indices[-1]), f\"WHAT!? {correct_indices[-1]} vs {len(indices_used_for_data)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a56268a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 20243/20243 [00:07<00:00, 2662.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.6499530701971(316.6066788519488) +- 308.4157781758335  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_ranking(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=None):\n",
    "    '''\n",
    "    Get the rank of the prediction from the applicable actions.\n",
    "    Returns (rank, [list_of_indices before <rank>])\n",
    "    '''\n",
    "    if distance == \"euclidean\":\n",
    "        dist = ((emb_for_comparison-pred)**2).sum(axis=1)\n",
    "    elif distance == \"cosine\":\n",
    "        dist = 1 - (emb_for_comparison.dot(pred))/(np.linalg.norm(emb_for_comparison, axis=1)*np.linalg.norm(pred))\n",
    "\n",
    "    maxy = max(dist)\n",
    "\n",
    "    list_of_indices = []\n",
    "    for attempt in range(dist.shape[0]):\n",
    "        miny = dist.argmin()\n",
    "#         print(miny, correct_index, dist[correct_index], min(dist), maxy)\n",
    "        if dist[miny] == dist[correct_index]:\n",
    "#             print(i, attempt)\n",
    "            break\n",
    "        else:\n",
    "            list_of_indices.append(miny)\n",
    "            if k is not None and len(list_of_indices) == k:\n",
    "                return list_of_indices\n",
    "            dist[miny] = 100000\n",
    "    \n",
    "    # When the rank(correct_index) < k, then returns <rank, list>. So this extra condition - add some indices after rank(correct_index) to the list\n",
    "    if k is not None:\n",
    "        dist[miny] = 100000\n",
    "        for attempt in range(min(k, emb_for_comparison.shape[0]-1) - len(list_of_indices)):\n",
    "            miny = dist.argmin()\n",
    "            list_of_indices.append(miny)\n",
    "            dist[miny] = 100000\n",
    "        return list_of_indices\n",
    "    return attempt, list_of_indices\n",
    "\n",
    "def get_top_k_indices(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=1):\n",
    "    return get_ranking(pred, emb_for_comparison, correct_index, distance, k)\n",
    "    \n",
    "pred = model(torch.Tensor(X[int(main_df.shape[0]*0.8):]).to(device)).detach().cpu().numpy()\n",
    "l = []\n",
    "total = []\n",
    "for i in tqdm.tqdm(range(pred.shape[0])):\n",
    "    pred_for_i = pred[i]\n",
    "    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[int(main_df.shape[0]*0.8)+i]], correct_indices[int(main_df.shape[0]*0.8)+i]\n",
    "\n",
    "    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=\"euclidean\")\n",
    "    l.append(rank)\n",
    "    total.append(act_emb_for_i.shape[0])\n",
    "print(f\"{np.mean(l)}({np.mean(total)}) +- {np.std(l)}  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, pred, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7213fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/mangye16/ReID-Survey\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: pytorch Variable, with shape [m, d]\n",
    "      y: pytorch Variable, with shape [n, d]\n",
    "    Returns:\n",
    "      dist: pytorch Variable, with shape [m, n]\n",
    "    \"\"\"\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n",
    "    dist = xx + yy\n",
    "    dist.addmm_(1, -2, x, y.t())\n",
    "    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "    return dist\n",
    "\n",
    "def cosine_dist(x, y):\n",
    "    xy = x.matmul(y.t())\n",
    "\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.linalg.norm(x, axis=1).expand(n, m).t()\n",
    "    yy = torch.linalg.norm(y, axis=1).expand(m, n)\n",
    "    \n",
    "    return 1 - xy / (xx*yy)\n",
    "\n",
    "\n",
    "def softmax_weights(dist, mask):\n",
    "    max_v = torch.max(dist * mask, dim=1, keepdim=True)[0]\n",
    "    diff = dist - max_v\n",
    "    Z = torch.sum(torch.exp(diff) * mask, dim=1, keepdim=True) + 1e-6 # avoid division by zero\n",
    "    W = torch.exp(diff) * mask / Z\n",
    "    return W\n",
    "\n",
    "class WeightedRegularizedTriplet(object):\n",
    "    def __init__(self, dist=\"euclidean\"):\n",
    "        self.ranking_loss = nn.SoftMarginLoss()\n",
    "        self.dist = dist\n",
    "\n",
    "    def __call__(self, global_feat, labels):\n",
    "        if self.dist==\"euclidean\":\n",
    "            dist_mat = euclidean_dist(global_feat, global_feat)\n",
    "        elif self.dist==\"cosine\":\n",
    "            dist_mat = cosine_dist(global_feat, global_feat) ####### NEEEDS TO BE CHANGED!!!!!!!!!!!\n",
    "\n",
    "        N = dist_mat.size(0)\n",
    "        # shape [N, N]\n",
    "        is_pos = labels.expand(N, N).eq(labels.expand(N, N).t()).float()\n",
    "        is_neg = labels.expand(N, N).ne(labels.expand(N, N).t()).float()\n",
    "\n",
    "        # `dist_ap` means distance(anchor, positive)\n",
    "        # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "        dist_ap = dist_mat * is_pos\n",
    "        dist_an = dist_mat * is_neg\n",
    "\n",
    "        weights_ap = softmax_weights(dist_ap, is_pos)\n",
    "        weights_an = softmax_weights(-dist_an, is_neg)\n",
    "        furthest_positive = torch.sum(dist_ap * weights_ap, dim=1)\n",
    "        closest_negative = torch.sum(dist_an * weights_an, dim=1)\n",
    "\n",
    "        y = furthest_positive.new().resize_as_(furthest_positive).fill_(1)\n",
    "        loss = self.ranking_loss(closest_negative - furthest_positive, y)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae378842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(main_df.shape[0]*0.8))\n",
    "test_idx = np.arange(int(main_df.shape[0]*0.8), main_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "\n",
    "test_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"reactant\"]))).to(device)\n",
    "test_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"product\"]))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2011ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.GIN = torch.load(\"models/zinc2m_gin.pth\")\n",
    "        self.DENSE = torch.load(mse_model_path)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.GIN(x1, x1.node_feature.float())[\"graph_feature\"]\n",
    "        out2 = self.GIN(x2, x2.node_feature.float())[\"graph_feature\"]\n",
    "        \n",
    "        out = torch.concatenate([out1, out2], axis=1)\n",
    "        out = self.DENSE(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532f0e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "action_embeddings = get_action_dataset_embeddings(gin_model)\n",
    "# action_embeddings = _action_embeddings.copy()\n",
    "action_embeddings_norm = np.linalg.norm(action_embeddings)\n",
    "\n",
    "for distance_metric, negative_method, topk, emb_model_update in itertools.product([\"euclidean\"], [\"all\"], [10], [1]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    \n",
    "    model = PolicyNetwork().to(device)\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "    criterion = WeightedRegularizedTriplet()\n",
    "    \n",
    "    metric_dict = {\"rank(cosine)\": [], \"rank(euclidean)\": [], \"rmse\": [], \"cos_dist\": []}\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "            outputs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size])\n",
    "\n",
    "            # Calc negatives\n",
    "            negatives = []\n",
    "            \n",
    "            for _i in range(outputs.shape[0]):\n",
    "                act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[train_idx[i+_i]]], correct_indices[train_idx[i+_i]]\n",
    "                curr_out = outputs[_i].detach().cpu().numpy()\n",
    "\n",
    "                if negative_method == \"applicable\":\n",
    "                    top = get_top_k_indices(curr_out, act_emb_for_i, correct_index, distance=distance_metric, k=50)\n",
    "                    negatives.append(act_emb_for_i[top])\n",
    "                \n",
    "                elif negative_method == \"all\":\n",
    "                    if distance_metric == \"euclidean\":\n",
    "                        dist = np.linalg.norm(action_embeddings - curr_out)\n",
    "                    elif distance_metric == \"cosine\":\n",
    "                        dist = (1 - action_embeddings.dot(curr_out)) / (action_embeddings_norm *np.linalg.norm(curr_out))\n",
    "                    sorted_idx = np.argsort(dist)[:topk] # get topk\n",
    "                    sorted_idx = sorted_idx[sorted_idx != correct_index] # Remove if correct index in list\n",
    "                    negatives.append(action_embeddings[sorted_idx])\n",
    "                        \n",
    "            negatives = torch.Tensor(np.concatenate(negatives, axis=0)).to(device)\n",
    "                                \n",
    "            # get targets\n",
    "            targets = torch.Tensor(get_action_embedding(embedding_model, main_df.iloc[i:i+batch_size][main_df.columns[1:-1]])).to(device)\n",
    "                                \n",
    "            # Calc loss\n",
    "            inputs = torch.concat([outputs, targets, negatives])\n",
    "            labels = torch.concat([torch.arange(outputs.shape[0]), torch.arange(targets.shape[0]), torch.full((negatives.shape[0],), -1)]).to(device)\n",
    "            loss = criterion(inputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print ('{:.6f}({})'.format(loss.item(), epoch), end='  ')\n",
    "        \n",
    "        # SWITCH INDENT HERE ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            margin_string = f\"# emb_model_update = {emb_model_update} | -ve_method = {negative_method} | dist_metric = {distance_metric} | topk = {topk} #\"\n",
    "            print(\"#\" * len(margin_string))\n",
    "            print(margin_string)\n",
    "            print(\"#\" * len(margin_string))\n",
    "\n",
    "            # Predictions and action component-wise loss\n",
    "            pred = model(test_reactants, test_products).detach().cpu().numpy() \n",
    "            true = get_action_embedding(embedding_model, main_df.iloc[test_idx][main_df.columns[1:-1]])\n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_dist\", \"rank(euclidean)\", \"rank(cosine)\"])\n",
    "\n",
    "            # Print Test metrics\n",
    "            metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean() )\n",
    "            metric_dict[\"cos_dist\"].append( ((pred*true).sum(axis=1) / np.linalg.norm(pred, axis=1) / np.linalg.norm(true, axis=1)).mean() )\n",
    "\n",
    "            # Print Test metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[test_idx[i]]], correct_indices[test_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=dist)\n",
    "                    l.append(rank)\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                metric_dict[f\"rank({dist})\"].append(np.mean(l))\n",
    "\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "            \n",
    "        # Update embedding model and action_embeddings\n",
    "        if epoch % emb_model_update == 0:\n",
    "            embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "            action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "            action_embeddings_norm = np.linalg.norm(action_embeddings)\n",
    "            \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"rank\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(distance_metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # save everything\n",
    "    folder = f\"models/supervised/5step/emb_model_update={emb_model_update}||-ve_method={negative_method}||dist_metric={distance_metric}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "    json.dump({\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"distance_metric\": distance_metric,\n",
    "        \"negative_method\": negative_method,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5e922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
