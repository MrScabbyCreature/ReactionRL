{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0357fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MAIN_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from offlineRL_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82c2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:3\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "device = torch.device(f\"cuda:{d}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17315ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(model_type=\"actor-critic\", steps=1, actor_loss=\"mse\", index_selection=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d2b31",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bf48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100996, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"datasets/offlineRL/{args.steps}steps_train.csv\", index_col=0).sample(frac=1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79970588",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939ca6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'offlineRL_utils.ActorCritic'>\n",
      "Namespace(actor_loss='mse', index_selection='random', model_type='actor-critic', steps=1)\n"
     ]
    }
   ],
   "source": [
    "if args.model_type == \"actor\":\n",
    "    train_actor = True\n",
    "    train_critic = False\n",
    "    model = ActorNetwork()\n",
    "    \n",
    "if args.model_type == \"critic\":\n",
    "    train_actor = False\n",
    "    train_critic = True\n",
    "    model = CriticNetwork()\n",
    "    \n",
    "if args.model_type == \"actor-critic\":\n",
    "    train_actor = True\n",
    "    train_critic = True\n",
    "    model = ActorCritic()\n",
    "\n",
    "model = model.to(device)\n",
    "print(type(model))\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97627d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84968, 17)\n"
     ]
    }
   ],
   "source": [
    "from action_utils import dataset as action_dataset\n",
    "print(action_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1411bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ga`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Al`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ti`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ta`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ru`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `As`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cd`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cr`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pt`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 6.95 s, total: 3min 37s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "action_rsigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"rsig\"])))\n",
    "action_psigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"psig\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19996872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100996/100996 [03:23<00:00, 495.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_applicable_indices = []\n",
    "correct_action_dataset_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, train_df.iterrows()), total=train_df.shape[0]):\n",
    "with Pool(35) as p:\n",
    "    for indices_used_for_data, correct_app_idx, correct_act_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, train_df.iterrows(), chunksize=50), total=train_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_applicable_indices.append(correct_app_idx)\n",
    "        correct_action_dataset_indices.append(correct_act_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7ebb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(train_df.shape[0]*0.8))\n",
    "valid_idx = np.arange(int(train_df.shape[0]*0.8), train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a82b23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10099,) (5050,)\n"
     ]
    }
   ],
   "source": [
    "# DO NOT USE THIS CELL\n",
    "train_idx = np.arange(0, int(train_df.shape[0]*0.1))\n",
    "valid_idx = np.arange(int(train_df.shape[0]*0.95), train_df.shape[0])\n",
    "print(train_idx.shape, valid_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8b6170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10099 10099 10099 10099\n",
      "5050 5050 5050 5050\n",
      "CPU times: user 2min 9s, sys: 3.93 s, total: 2min 13s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "if train_critic:\n",
    "    train_rsigs = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[train_idx][\"rsig\"]))).to(device)\n",
    "    train_psigs = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[train_idx][\"psig\"]))).to(device)\n",
    "\n",
    "valid_reactants = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[valid_idx][\"reactant\"]))).to(device)\n",
    "valid_products = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[valid_idx][\"product\"]))).to(device)\n",
    "if train_critic:\n",
    "    valid_rsigs = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[valid_idx][\"rsig\"]))).to(device)\n",
    "    valid_psigs = data.Molecule.pack(list(map(molecule_from_smile, train_df.iloc[valid_idx][\"psig\"]))).to(device)\n",
    "\n",
    "# COMMENT THESE!!!\n",
    "print(train_reactants.batch_size, train_products.batch_size, train_rsigs.batch_size, train_psigs.batch_size)\n",
    "print(valid_reactants.batch_size, valid_products.batch_size, valid_rsigs.batch_size, valid_psigs.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d96642",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_lr = 3e-4\n",
    "critic_lr = 1e-3\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "topk = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faaf8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_actor:\n",
    "    actor_optimizer = torch.optim.Adam(model.parameters(), lr=actor_lr)  \n",
    "if train_critic:\n",
    "    critic_optimizer = torch.optim.Adam(model.parameters(), lr=critic_lr)  \n",
    "critic_loss_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67eb3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For actor log prob calc\n",
    "actor_log_std = nn.Parameter(torch.zeros(model.actor.last_layer.out_features, dtype=torch.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1ab395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embeddings init\n",
    "embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "action_embeddings = get_action_dataset_embeddings(embedding_model, action_rsigs, action_psigs)\n",
    "action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8f4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper inits\n",
    "best_rank = 10000\n",
    "best_metric = -100\n",
    "best_model = None\n",
    "actor_metric_dict = {\"cos_rank_mean\": [], \"euc_rank_mean\": [], \"cos_rank_std\": [], \"euc_rank_std\": [], \n",
    "               \"cos_rank_tot\": [], \"euc_rank_tot\": [], \"rmse\": [], \"cos_sim\": [], \"time(epoch_start-now)\": []}\n",
    "critic_metric_dict = {\"GT_acc\": [], \"GT_rec\": [], \"GT_prec\": [], \"GT_f1\": [], \n",
    "                \"others_acc\": [], \"others_rec\": [], \"others_prec\": [], \"others_f1\": [], \n",
    "                \"mean_acc\": [], \"mean_rec\": [], \"mean_prec\": [], \"mean_f1\": [],  \"time(epoch_start-now)\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d4c831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(actor_loss='mse', index_selection='random', model_type='actor-critic', steps=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aa54d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [00:52<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5. Batch 9856/9971. Actor loss = 0.067756 || critic loss = 0.034126\n",
      "######################################################################################\n",
      "# model_type--actor-critic || steps--1 || actor_loss--mse || index_selection--random #\n",
      "######################################################################################\n",
      "╒════╤═════════╤═══════════╤═════════════════╤════════════════╤════════════════╤═════════════════╤════════════════╤════════════════╤═════════════════════════╕\n",
      "│    │    rmse │   cos_sim │   euc_rank_mean │   euc_rank_std │   euc_rank_tot │   cos_rank_mean │   cos_rank_std │   cos_rank_tot │ time(epoch_start-now)   │\n",
      "╞════╪═════════╪═══════════╪═════════════════╪════════════════╪════════════════╪═════════════════╪════════════════╪════════════════╪═════════════════════════╡\n",
      "│  1 │ 3.85273 │  0.812173 │         453.246 │        572.452 │        1731.61 │         414.946 │        548.617 │        1731.61 │ 1.00 min                │\n",
      "╘════╧═════════╧═══════════╧═════════════════╧════════════════╧════════════════╧═════════════════╧════════════════╧════════════════╧═════════════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:06<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 453.2463942307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [00:54<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5. Batch 9856/9971. Actor loss = 0.052480 || critic loss = 0.019395\n",
      "######################################################################################\n",
      "# model_type--actor-critic || steps--1 || actor_loss--mse || index_selection--random #\n",
      "######################################################################################\n",
      "╒════╤═════════╤═══════════╤═════════════════╤════════════════╤════════════════╤═════════════════╤════════════════╤════════════════╤═════════════════════════╕\n",
      "│    │    rmse │   cos_sim │   euc_rank_mean │   euc_rank_std │   euc_rank_tot │   cos_rank_mean │   cos_rank_std │   cos_rank_tot │ time(epoch_start-now)   │\n",
      "╞════╪═════════╪═══════════╪═════════════════╪════════════════╪════════════════╪═════════════════╪════════════════╪════════════════╪═════════════════════════╡\n",
      "│  2 │ 3.31489 │  0.862039 │         349.646 │        493.438 │        1731.61 │         295.719 │        437.178 │        1731.61 │ 1.02 min                │\n",
      "╘════╧═════════╧═══════════╧═════════════════╧════════════════╧════════════════╧═════════════════╧════════════════╧════════════════╧═════════════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████████████████████████▌                                                                                                       | 16/42 [00:03<00:05,  4.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39663/1482914763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Update embedding model and action_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0maction_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action_dataset_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_rsigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_psigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0maction_embeddings_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ReactionRL/offlineRL_utils.py\u001b[0m in \u001b[0;36mget_action_dataset_embeddings\u001b[0;34m(model, action_rsigs, action_psigs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mbatch_rsig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_rsigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mbatch_psig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_psigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0maction_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_action_embedding_from_packed_molecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rsig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_psig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0maction_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/graph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/graph.py\u001b[0m in \u001b[0;36msubbatch\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPackedGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mask\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \"\"\"\n\u001b[0;32m-> 1636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/graph.py\u001b[0m in \u001b[0;36mgraph_mask\u001b[0;34m(self, index, compact)\u001b[0m\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m         \u001b[0medge_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1600\u001b[0;31m         \u001b[0medge_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1601\u001b[0m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standarize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(1, epochs+1):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for i in tqdm.tqdm(range(0, train_reactants.batch_size - batch_size, batch_size)):\n",
    "        # Forward pass\n",
    "        actor_actions = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size], \"actor\")\n",
    "\n",
    "        if train_critic or args.actor_loss == \"PG\":\n",
    "            # Calc negatives\n",
    "            negative_indices = []\n",
    "\n",
    "            for _i in range(actor_actions.shape[0]):\n",
    "                correct_action_dataset_index = correct_action_dataset_indices[train_idx[i+_i]]\n",
    "                if args.index_selection == \"random\":\n",
    "                    size = min(topk, action_embedding_indices[train_idx[i+_i]].shape[0])\n",
    "                    negative_indices.append(np.random.choice(correct_action_dataset_index, size=(size,), replace=False))\n",
    "                if args.index_selection == \"closest\":\n",
    "                    curr_out = actor_actions[_i].detach()\n",
    "                    dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                    sorted_idx = torch.argsort(dist)[:topk] # get topk\n",
    "                    sorted_idx = sorted_idx[sorted_idx != correct_action_dataset_index] # Remove if correct index in list\n",
    "                    negative_indices.append(sorted_idx)\n",
    "\n",
    "        # critic update\n",
    "        if train_critic:\n",
    "            batch_reactants = train_reactants[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_products = train_products[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_rsigs = action_rsigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_psigs = action_psigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_q_targets = torch.Tensor(sum([[1] + [0] * negative_indices[_i].shape[0] for _i in range(actor_actions.shape[0])], [])).view(-1, 1)\n",
    "\n",
    "\n",
    "            critic_qs = model(batch_reactants.to(device), batch_products.to(device), batch_rsigs.to(device), batch_psigs.to(device), \"critic\")\n",
    "            critic_loss = critic_loss_criterion(critic_qs, batch_q_targets.to(device))\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "        # actor update\n",
    "        if train_actor:\n",
    "            actor_actions = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size], \"actor\")\n",
    "            if args.actor_loss ==\"mse\":\n",
    "                actor_loss = nn.MSELoss()(actor_actions, \n",
    "                                          get_action_embedding_from_packed_molecule(embedding_model,\n",
    "                                                                                    train_rsigs[i:i+batch_size], \n",
    "                                                                                    train_psigs[i:i+batch_size]))\n",
    "            elif args.actor_loss == \"PG\":\n",
    "                normal_dist = torch.distributions.Normal(actor_actions, actor_log_std.exp())\n",
    "                positives = get_action_embedding_from_packed_molecule(embedding_model, train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "                positive_log_pi = normal_dist.log_prob(positives)\n",
    "                negative_log_pi = []\n",
    "                for _i, _indices in enumerate(negative_indices):\n",
    "                    normal_dist = torch.distributions.Normal(actor_actions[_i], actor_log_std.exp())\n",
    "                    negative_log_pi.append(normal_dist.log_prob(action_embeddings[_indices]))\n",
    "                negative_log_pi = torch.concatenate(negative_log_pi, axis=0)\n",
    "\n",
    "                actor_loss = torch.concatenate([-positive_log_pi, (1/(topk*2))*negative_log_pi], axis=0).sum(-1, keepdim=True).mean() # Using R = 1 for positives, and R = -1/2topk for negatives \n",
    "            else:\n",
    "                raise Exception(f\"Unexpected actor loss {args.actor_loss}\")\n",
    "\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "        # Emptry any cache (free GPU memory)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print (f'Epoch {epoch}/{epochs}. Batch {i}/{train_reactants.batch_size - batch_size}. Actor loss = {actor_loss.item():.6f} || critic loss = {critic_loss.item():.6f}')#, end='\\r')\n",
    "    \n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        d = vars(args)\n",
    "        margin_string = \"# \" + \" || \".join([f\"{k}--{d[k]}\" for k in d]) + \" #\"\n",
    "        print(\"#\" * len(margin_string))\n",
    "        print(margin_string)\n",
    "        print(\"#\" * len(margin_string))\n",
    "\n",
    "        if train_actor: # Display actor metrics\n",
    "            # Predictions and action component-wise loss\n",
    "            pred = torch.concatenate([model(valid_reactants[i:i+batch_size], \n",
    "                                            valid_products[i:i+batch_size], \n",
    "                                            valid_rsigs[i:i+batch_size], \n",
    "                                            valid_psigs[i:i+batch_size])[0].detach() \\\n",
    "                                      for i in range(0, valid_reactants.batch_size-batch_size, batch_size)], axis=0)\n",
    "            true = get_action_embedding_from_packed_molecule(embedding_model, valid_rsigs[:pred.shape[0]], valid_psigs[:pred.shape[0]]) \n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_sim\", \"euc_rank_mean\", \"euc_rank_std\", \"euc_rank_tot\", \"cos_rank_mean\", \"cos_rank_std\", \"cos_rank_tot\", \"time(epoch_start-now)\"])\n",
    "\n",
    "            # Print valid metrics\n",
    "            actor_metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean().item() )\n",
    "            actor_metric_dict[\"cos_sim\"].append( ((pred*true).sum(axis=1) / torch.linalg.norm(pred, axis=1) / torch.linalg.norm(true, axis=1)).mean().item() )\n",
    "\n",
    "            # Print valid metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_applicable_index = action_embeddings[action_embedding_indices[valid_idx[i]]], correct_applicable_indices[valid_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_applicable_index, distance=dist)\n",
    "                    l.append(rank.item())\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                actor_metric_dict[f\"{dist[:3]}_rank_mean\"].append(np.mean(l))\n",
    "                actor_metric_dict[f\"{dist[:3]}_rank_std\"].append(np.std(l))\n",
    "                actor_metric_dict[f\"{dist[:3]}_rank_tot\"].append(np.mean(total))\n",
    "\n",
    "            actor_metric_dict[\"time(epoch_start-now)\"].append(f\"{(time.time()-start_time)/60:.2f} min\")\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [actor_metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "        \n",
    "        if train_critic and not train_actor: # Display critic metrics - only if no actor\n",
    "            # Predict for GT\n",
    "            GT_pred_qs = (torch.concatenate([model(valid_reactants[i:i+batch_size], \n",
    "                         valid_products[i:i+batch_size], \n",
    "                         valid_rsigs[i:i+batch_size], \n",
    "                         valid_psigs[i:i+batch_size]).detach() for i in range(0, valid_reactants.batch_size-batch_size, batch_size)], axis=0).cpu().numpy() > 0.5).astype(int)\n",
    "            GT_true_qs = np.ones_like(GT_pred_qs)\n",
    "\n",
    "            # Pred for others\n",
    "            negative_indices = []\n",
    "\n",
    "            for i in valid_idx:\n",
    "                correct_action_dataset_index = correct_action_dataset_indices[i]\n",
    "                curr_out = action_embeddings[correct_action_dataset_index]\n",
    "                dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "\n",
    "                # Get the closest that is not GT\n",
    "                sorted_idx = torch.argsort(dist)[:2]\n",
    "                sorted_idx = sorted_idx[sorted_idx != correct_action_dataset_index] # Remove if correct index in list\n",
    "                sorted_idx = sorted_idx[:1]\n",
    "                negative_indices.append(sorted_idx)\n",
    "\n",
    "            valid_batch_reactants = valid_reactants[sum([[i]*negative_indices[i].shape[0] for i in range(valid_idx.shape[0])], [])].to(device)\n",
    "            valid_batch_products = valid_products[sum([[i]*negative_indices[i].shape[0] for i in range(valid_idx.shape[0])], [])].to(device)\n",
    "            valid_batch_rsigs = action_rsigs[torch.concatenate(negative_indices)].to(device)\n",
    "            valid_batch_psigs = action_psigs[torch.concatenate(negative_indices)].to(device)\n",
    "\n",
    "            others_pred_qs = (torch.concatenate([model(valid_batch_reactants[i:i+batch_size], \n",
    "                         valid_batch_products[i:i+batch_size], \n",
    "                         valid_batch_rsigs[i:i+batch_size], \n",
    "                         valid_batch_psigs[i:i+batch_size]).detach() for i in range(0, valid_batch_reactants.batch_size-batch_size, batch_size)], axis=0).cpu().numpy() > 0.5).astype(int)\n",
    "            others_true_qs = np.zeros_like(others_pred_qs)\n",
    "\n",
    "            # Update metrics (with inverted labels -- sklearn considers 0 as true class in confusion matrix)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(GT_true_qs, GT_pred_qs), precision_recall_fscore_support(GT_true_qs, GT_pred_qs, average=\"binary\")\n",
    "            critic_metric_dict[\"GT_acc\"].append(acc); critic_metric_dict[\"GT_rec\"].append(rec); critic_metric_dict[\"GT_prec\"].append(prec); critic_metric_dict[\"GT_f1\"].append(f1)\n",
    "\n",
    "            # 1-others in prec_rec_f1 because sklearn wants true class as 1 and others has true class 0 (only for the sake of metric scores)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(others_true_qs, others_pred_qs), precision_recall_fscore_support(1-others_true_qs, 1-others_pred_qs, average=\"binary\") \n",
    "            critic_metric_dict[\"others_acc\"].append(acc); critic_metric_dict[\"others_rec\"].append(rec); critic_metric_dict[\"others_prec\"].append(prec); critic_metric_dict[\"others_f1\"].append(f1)\n",
    "\n",
    "            mean_pred_qs = np.concatenate([GT_pred_qs, others_pred_qs], axis=0)\n",
    "            mean_true_qs = np.concatenate([GT_true_qs, others_true_qs], axis=0)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(mean_true_qs, mean_pred_qs), precision_recall_fscore_support(mean_true_qs, mean_pred_qs, average=\"binary\")\n",
    "            critic_metric_dict[\"mean_acc\"].append(acc); critic_metric_dict[\"mean_rec\"].append(rec); critic_metric_dict[\"mean_prec\"].append(prec); critic_metric_dict[\"mean_f1\"].append(f1)\n",
    "\n",
    "            # Print\n",
    "            metric_df = pd.DataFrame(columns=[\"GT_acc\", \"GT_rec\", \"GT_prec\", \"GT_f1\", \"others_acc\", \"others_rec\", \"others_prec\", \"others_f1\", \n",
    "                                              \"mean_acc\", \"mean_rec\", \"mean_prec\", \"mean_f1\",  \"time(epoch_start-now)\"])\n",
    "\n",
    "            critic_metric_dict[\"time(epoch_start-now)\"].append(f\"{(time.time()-start_time)/60:.2f} min\")\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [critic_metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "\n",
    "            \n",
    "\n",
    "            # Update best model (with GT f1 - we want critic for best GT)\n",
    "            metric_for_best_model = \"GT_f1\"\n",
    "            curr_metric = metric_dict[metric_for_best_model][-1]\n",
    "            if curr_metric > best_metric:\n",
    "                best_metric = curr_metric\n",
    "                best_model = type(model)()\n",
    "                best_model.load_state_dict(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "                print(f\"BEST MODEL UPDATED! BEST {metric_for_best_model} = {best_metric}\")\n",
    "\n",
    "        \n",
    "\n",
    "    # Update embedding model and action_embeddings\n",
    "    embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model, action_rsigs, action_psigs)\n",
    "    action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "\n",
    "    # Update best model\n",
    "    if actor_metric_dict[\"euc_rank_mean\"][-1] < best_rank:\n",
    "        best_rank = actor_metric_dict[\"euc_rank_mean\"][-1]\n",
    "        best_model = type(model)()\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "        best_epoch = epoch\n",
    "        print(f\"BEST MODEL UPDATED! BEST RANK = {best_rank}\")\n",
    "\n",
    "# save everything\n",
    "folder = f\"models/supervised/{args.model_type}/steps={args.steps}||actor_loss={args.actor_loss}\"\n",
    "os.makedirs(folder, exist_ok = True)\n",
    "\n",
    "if train_actor:\n",
    "    metric_dict = actor_metric_dict\n",
    "    \n",
    "    # Save fig\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"mean\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(f\"Offline RL (steps={args.steps})\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show() # COMMENT THIS IN FINAL CODE\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "else:\n",
    "    metric_dict = critic_metric_dict\n",
    "\n",
    "torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "json.dump({\n",
    "    \"steps(trajectory length)\": args.steps,\n",
    "    \"actor_lr\": actor_lr,\n",
    "    \"critic_lr\": critic_lr,\n",
    "    \"epochs\": epochs, \n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_samples\": train_idx.shape,\n",
    "    \"valid_samples\": valid_idx.shape,\n",
    "    \"topk\": topk,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"best_rank\": best_rank\n",
    "}, open(os.path.join(folder, \"config.txt\"), 'w'))\n",
    "print(\"Saved model at\", folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5e40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61697513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12764773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
