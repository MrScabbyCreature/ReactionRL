{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MAIN_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f862867f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "\n",
    "from action_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeee3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from action_utils import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d77759",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mols = pickle.load(open(\"datasets/my_uspto/unique_start_mols.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660f7320",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107828it [03:55, 458.31it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107828, 10)\n",
      "(107828, 10)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "main_df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "N = 100000\n",
    "np.random.seed(42)\n",
    "steps = 5\n",
    "\n",
    "def generate_train_data(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    index = []\n",
    "    \n",
    "    # Get sequences\n",
    "    try:\n",
    "        for i in range(steps):\n",
    "            actions = get_applicable_actions(mol)\n",
    "            if actions.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            # Apply a random action\n",
    "            rand_idx = np.random.randint(0, actions.shape[0])\n",
    "            product = apply_action(mol, *actions.iloc[rand_idx])\n",
    "\n",
    "            # Add it to df\n",
    "            df.loc[df.shape[0], :] = [Chem.MolToSmiles(mol)] + actions.iloc[rand_idx].tolist() + [Chem.MolToSmiles(product)]\n",
    "            index.append(actions.iloc[rand_idx].name)\n",
    "\n",
    "            # Next reactant = product\n",
    "            mol = product\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    \n",
    "    # Fix index\n",
    "    df.index = index\n",
    "    \n",
    "    # Make combinations for multi-step possibilities of source-->target\n",
    "    for i in range(df.shape[0]-1, 0, -1):\n",
    "        new_df = df.iloc[:i].copy()\n",
    "        new_df[\"product\"] = df.iloc[i][\"product\"]\n",
    "        df = pd.concat([df, new_df])\n",
    "        \n",
    "    return df\n",
    "\n",
    "df_list = []\n",
    "final_shape = 0\n",
    "# Create dataset for 5 step pred\n",
    "with Pool(30) as p, tqdm.tqdm(total=N) as pbar:\n",
    "    while final_shape < N:\n",
    "        smiles = np.random.choice(start_mols, size=(1000,))\n",
    "\n",
    "        for new_df in p.imap_unordered(generate_train_data, smiles, chunksize=10):\n",
    "            df_list.append(new_df)\n",
    "            final_shape += new_df.shape[0]\n",
    "            \n",
    "        pbar.update(final_shape - pbar.n)\n",
    "\n",
    "main_df = pd.concat(df_list)\n",
    "del df_list\n",
    "print(main_df.shape)\n",
    "\n",
    "# randomize\n",
    "main_df = pd.concat([main_df[:int(main_df.shape[0]*0.8)].sample(frac=1), main_df[int(main_df.shape[0]*0.8):].sample(frac=1)])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58b5a",
   "metadata": {},
   "source": [
    "# Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e1a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc8c9fc8ab0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3432cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48289f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 23151.4941\n",
      "Epoch 2, Loss: 13421.6543\n",
      "Epoch 3, Loss: 5006.6743\n",
      "Epoch 4, Loss: 1424.6224\n",
      "Epoch 5, Loss: 517.5692\n",
      "Epoch 6, Loss: 364.8164\n",
      "Epoch 7, Loss: 346.8831\n",
      "Epoch 8, Loss: 332.0376\n",
      "Epoch 9, Loss: 334.5102\n",
      "Epoch 10, Loss: 327.3152\n",
      "\n",
      "FINAL TEST LOSS: 59.57931137084961\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.49 s, sys: 1.26 s, total: 8.75 s\n",
      "Wall time: 8.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (4): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (last_layer): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden=1, hidden_size=50):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(num_hidden):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            \n",
    "        self.last_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        out = self.last_layer(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "def train(X, Y, num_hidden=1, hidden_size=50, lr=1e-2, bs=64, epochs=100):\n",
    "    train_X = torch.Tensor(X[:int(X.shape[0]*0.7)]).to(device)\n",
    "    train_Y = torch.Tensor(Y[:int(Y.shape[0]*0.7)]).to(device)\n",
    "\n",
    "    test_X = torch.Tensor(X[int(X.shape[0]*0.7):]).to(device)\n",
    "    test_Y = torch.Tensor(Y[int(Y.shape[0]*0.7):]).to(device)\n",
    "    \n",
    "    model = NeuralNet(train_X.shape[1], train_Y.shape[1], num_hidden=num_hidden, hidden_size=hidden_size).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "\n",
    "    loss_list = []\n",
    "    test_loss = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, train_X.shape[0], batch_size):\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(train_X[i:i+batch_size])\n",
    "            loss = criterion(outputs, train_Y[i:i+batch_size])\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        print ('Epoch {}, Loss: {:.4f}'.format(epoch+1, loss.item()))\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss.append(criterion(model(test_X), test_Y).item()) \n",
    "    print(\"\\nFINAL TEST LOSS:\", test_loss[-1])\n",
    "        \n",
    "    plt.plot(loss_list[5:], label=\"training loss\")\n",
    "    plt.plot(test_loss[5:], label=\"test loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "from sklearn.datasets import make_regression\n",
    "x, y = make_regression(n_samples=5000, n_features=20, noise=2, random_state=42)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "%time train(x, y, num_hidden=2, hidden_size=20, lr=1e-2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662cf55",
   "metadata": {},
   "source": [
    "# Embedding type 2 - GIN training using attribute masking on clintox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835d1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchdrug import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32366ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"models/zinc2m_gin.pth\"\n",
    "gin_model = torch.load(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cda6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_from_smile(smile):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "    return mol\n",
    "\n",
    "def get_mol_embedding(model, smiles):\n",
    "    # deepchem - attribute masking\n",
    "    if isinstance(smiles, str):\n",
    "        mol = molecule_from_smile(smiles)\n",
    "    else:\n",
    "        mol = list(map(molecule_from_smile, smiles))\n",
    "        mol = data.Molecule.pack(mol)\n",
    "    mol = mol.to(device)\n",
    "    emb = model(mol, mol.node_feature.float())[\"graph_feature\"]\n",
    "    return emb.detach().cpu().numpy()\n",
    "\n",
    "def get_atom_embedding(model, smiles, idx):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    return emb.detach().cpu()\n",
    "\n",
    "def get_action_embedding(model, action_df):\n",
    "    rsub, rcen, rsig, _, psub, pcen, psig, __ = [action_df[c] for c in action_df.columns]\n",
    "#     print(get_mol_embedding(model, rsub).shape)\n",
    "#     print(get_atom_embedding(model, rsig, rcen).shape)\n",
    "#     print(get_mol_embedding(model, rsig).shape)\n",
    "#     print(get_mol_embedding(model, psub).shape)\n",
    "#     print(get_atom_embedding(model, psig, pcen).shape)\n",
    "#     print(get_mol_embedding(model, psig).shape)\n",
    "    embedding = np.concatenate([\n",
    "#                         get_mol_embedding(model, rsub), \n",
    "#                         get_atom_embedding(model, rsig, rcen) / 5, \n",
    "                        get_mol_embedding(model, rsig), \n",
    "#                         get_mol_embedding(model, psub), \n",
    "#                         get_atom_embedding(model, psig, pcen) / 5, \n",
    "                        get_mol_embedding(model, psig)\n",
    "                    ], axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6003605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                                             | 10/1685 [00:07<17:41,  1.58it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "  9%|█████▌                                                       | 152/1685 [01:35<16:36,  1.54it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pb`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "  9%|█████▌                                                       | 153/1685 [01:36<15:59,  1.60it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `As`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 14%|████████▌                                                    | 237/1685 [02:28<14:31,  1.66it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ti`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 50%|██████████████████████████████▎                              | 839/1685 [08:31<08:59,  1.57it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ga`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "100%|████████████████████████████████████████████████████████████| 1685/1685 [16:46<00:00,  1.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107828, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "X = []\n",
    "for i in tqdm.tqdm(range(0, main_df.shape[0], batch_size)):\n",
    "    reactants = main_df[\"reactant\"][i:i+batch_size]\n",
    "    products = main_df[\"product\"][i:i+batch_size]\n",
    "    X.append(np.concatenate([get_mol_embedding(gin_model, reactants), get_mol_embedding(gin_model, products)], axis=1))\n",
    "X = np.concatenate(X, axis=0)\n",
    "emb_len = X.shape[1]//2\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14ab411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 1685/1685 [09:23<00:00,  2.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107828, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "Y = []\n",
    "for i in tqdm.tqdm(range(0, main_df.shape[0], batch_size)):\n",
    "    Y.append(get_action_embedding(gin_model, main_df.iloc[i:i+batch_size][main_df.columns[1:-1]]))\n",
    "Y = np.concatenate(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1c369",
   "metadata": {},
   "source": [
    "### MSE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ffae30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0915\n",
      "Epoch 2, Loss: 0.0784\n",
      "Epoch 3, Loss: 0.0661\n",
      "Epoch 4, Loss: 0.0541\n",
      "Epoch 5, Loss: 0.0468\n",
      "Epoch 6, Loss: 0.0405\n",
      "Epoch 7, Loss: 0.0353\n",
      "Epoch 8, Loss: 0.0340\n",
      "Epoch 9, Loss: 0.0324\n",
      "Epoch 10, Loss: 0.0299\n",
      "Epoch 11, Loss: 0.0277\n",
      "Epoch 12, Loss: 0.0263\n",
      "Epoch 13, Loss: 0.0269\n",
      "Epoch 14, Loss: 0.0274\n",
      "Epoch 15, Loss: 0.0250\n",
      "Epoch 16, Loss: 0.0245\n",
      "Epoch 17, Loss: 0.0246\n",
      "Epoch 18, Loss: 0.0225\n",
      "Epoch 19, Loss: 0.0232\n",
      "Epoch 20, Loss: 0.0217\n",
      "Epoch 21, Loss: 0.0206\n",
      "Epoch 22, Loss: 0.0208\n",
      "Epoch 23, Loss: 0.0238\n",
      "Epoch 24, Loss: 0.0207\n",
      "Epoch 25, Loss: 0.0182\n",
      "Epoch 26, Loss: 0.0180\n",
      "Epoch 27, Loss: 0.0195\n",
      "Epoch 28, Loss: 0.0184\n",
      "Epoch 29, Loss: 0.0199\n",
      "Epoch 30, Loss: 0.0212\n",
      "Epoch 31, Loss: 0.0223\n",
      "Epoch 32, Loss: 0.0182\n",
      "Epoch 33, Loss: 0.0210\n",
      "Epoch 34, Loss: 0.0177\n",
      "Epoch 35, Loss: 0.0167\n",
      "Epoch 36, Loss: 0.0167\n",
      "Epoch 37, Loss: 0.0165\n",
      "Epoch 38, Loss: 0.0164\n",
      "Epoch 39, Loss: 0.0179\n",
      "Epoch 40, Loss: 0.0188\n",
      "Epoch 41, Loss: 0.0214\n",
      "Epoch 42, Loss: 0.0181\n",
      "Epoch 43, Loss: 0.0167\n",
      "Epoch 44, Loss: 0.0173\n",
      "Epoch 45, Loss: 0.0168\n",
      "Epoch 46, Loss: 0.0172\n",
      "Epoch 47, Loss: 0.0151\n",
      "Epoch 48, Loss: 0.0143\n",
      "Epoch 49, Loss: 0.0156\n",
      "Epoch 50, Loss: 0.0168\n",
      "Epoch 51, Loss: 0.0153\n",
      "Epoch 52, Loss: 0.0168\n",
      "Epoch 53, Loss: 0.0169\n",
      "Epoch 54, Loss: 0.0159\n",
      "Epoch 55, Loss: 0.0168\n",
      "Epoch 56, Loss: 0.0150\n",
      "Epoch 57, Loss: 0.0154\n",
      "Epoch 58, Loss: 0.0154\n",
      "Epoch 59, Loss: 0.0156\n",
      "Epoch 60, Loss: 0.0156\n",
      "Epoch 61, Loss: 0.0152\n",
      "Epoch 62, Loss: 0.0137\n",
      "Epoch 63, Loss: 0.0145\n",
      "Epoch 64, Loss: 0.0144\n",
      "Epoch 65, Loss: 0.0148\n",
      "Epoch 66, Loss: 0.0146\n",
      "Epoch 67, Loss: 0.0160\n",
      "Epoch 68, Loss: 0.0149\n",
      "Epoch 69, Loss: 0.0142\n",
      "Epoch 70, Loss: 0.0139\n",
      "Epoch 71, Loss: 0.0138\n",
      "Epoch 72, Loss: 0.0136\n",
      "Epoch 73, Loss: 0.0142\n",
      "Epoch 74, Loss: 0.0146\n",
      "Epoch 75, Loss: 0.0136\n",
      "Epoch 76, Loss: 0.0147\n",
      "Epoch 77, Loss: 0.0145\n",
      "Epoch 78, Loss: 0.0141\n",
      "Epoch 79, Loss: 0.0129\n",
      "Epoch 80, Loss: 0.0126\n",
      "Epoch 81, Loss: 0.0138\n",
      "Epoch 82, Loss: 0.0145\n",
      "Epoch 83, Loss: 0.0129\n",
      "Epoch 84, Loss: 0.0148\n",
      "Epoch 85, Loss: 0.0142\n",
      "Epoch 86, Loss: 0.0136\n",
      "Epoch 87, Loss: 0.0126\n",
      "Epoch 88, Loss: 0.0116\n",
      "Epoch 89, Loss: 0.0127\n",
      "Epoch 90, Loss: 0.0140\n",
      "Epoch 91, Loss: 0.0130\n",
      "Epoch 92, Loss: 0.0121\n",
      "Epoch 93, Loss: 0.0122\n",
      "Epoch 94, Loss: 0.0122\n",
      "Epoch 95, Loss: 0.0121\n",
      "Epoch 96, Loss: 0.0131\n",
      "Epoch 97, Loss: 0.0129\n",
      "Epoch 98, Loss: 0.0127\n",
      "Epoch 99, Loss: 0.0120\n",
      "Epoch 100, Loss: 0.0118\n",
      "\n",
      "FINAL TEST LOSS: 0.07068554311990738\n"
     ]
    }
   ],
   "source": [
    "model = train(X, Y, hidden_size=500, num_hidden=3, lr=1e-3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57264831",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"datasets/my_uspto/supervised_zinc_gin/mse_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddae391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89384, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▏                                                         | 94/1397 [00:30<05:47,  3.75it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 63%|██████████████████████████████████████▍                      | 881/1397 [05:08<02:53,  2.98it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cr`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 75%|█████████████████████████████████████████████▏              | 1051/1397 [06:14<02:05,  2.75it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cd`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 82%|█████████████████████████████████████████████████           | 1141/1397 [06:52<02:07,  2.01it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 84%|██████████████████████████████████████████████████▌         | 1176/1397 [07:05<01:07,  3.26it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ge`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 93%|████████████████████████████████████████████████████████    | 1304/1397 [07:58<00:35,  2.64it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pt`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 99%|███████████████████████████████████████████████████████████▍| 1383/1397 [08:30<00:04,  2.84it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Al`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      " 99%|███████████████████████████████████████████████████████████▋| 1389/1397 [08:33<00:03,  2.28it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ru`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "100%|███████████████████████████████████████████████████████████▊| 1393/1397 [08:35<00:01,  2.28it/s]/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ta`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "100%|████████████████████████████████████████████████████████████| 1397/1397 [08:37<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89384, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "action_dataset = pd.read_csv(\"datasets/my_uspto/action_dataset-filtered.csv\", index_col=0)\n",
    "action_dataset = action_dataset.loc[action_dataset[\"action_tested\"] & action_dataset[\"action_works\"]]\n",
    "action_dataset = action_dataset[[\"rsub\", \"rcen\", \"rsig\", \"rbond\", \"psub\", \"pcen\", \"psig\", \"pbond\"]]\n",
    "print(action_dataset.shape)\n",
    "\n",
    "def get_action_dataset_embeddings(model):\n",
    "    action_embeddings = []\n",
    "    for i in tqdm.tqdm(range(0, action_dataset.shape[0], batch_size)):\n",
    "        action_embeddings.append(get_action_embedding(model, action_dataset.iloc[i:i+batch_size]))\n",
    "    action_embeddings = np.concatenate(action_embeddings)\n",
    "    return action_embeddings\n",
    "\n",
    "action_embeddings = get_action_dataset_embeddings(gin_model)\n",
    "print(action_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33fb20",
   "metadata": {},
   "source": [
    "### Back to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92e20cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 107828/107828 [09:01<00:00, 199.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "def get_emb_indices_and_correct_idx(row):\n",
    "    if isinstance(row, tuple): # For pandas iterrows\n",
    "        row = row[1]\n",
    "    \n",
    "    # Applicable indices\n",
    "    applicable_actions_df = get_applicable_actions(Chem.MolFromSmiles(row[\"reactant\"]))\n",
    "    if applicable_actions_df.shape[0] == 0:\n",
    "        # If there are no applicable actions detected (rdkit problems)\n",
    "        indices_used_for_data = np.where((action_dataset.index == row.name))[0]\n",
    "        correct_idx = 0\n",
    "    else:\n",
    "        indices_used_for_data = np.where(action_dataset.index.isin(applicable_actions_df.index))[0]\n",
    "        \n",
    "        # Correct index\n",
    "        applicable_actions_df = applicable_actions_df.loc[action_dataset.iloc[indices_used_for_data].index]\n",
    "        correct_idx = (applicable_actions_df.index == row.name).argmax()\n",
    "\n",
    "    \n",
    "    return indices_used_for_data, correct_idx\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, main_df.iterrows()), total=main_df.shape[0]):\n",
    "with Pool(20) as p:\n",
    "    for indices_used_for_data, correct_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, main_df.iterrows(), chunksize=50), total=main_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_indices.append(correct_idx)\n",
    "\n",
    "        assert correct_indices[-1] < len(action_embedding_indices[-1]), f\"WHAT!? {correct_indices[-1]} vs {len(indices_used_for_data)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a56268a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 21566/21566 [00:16<00:00, 1276.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.63377538718353(335.46786608550497) +- 265.8036028688515  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_ranking(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=None):\n",
    "    '''\n",
    "    Get the rank of the prediction from the applicable actions.\n",
    "    Returns (rank, [list_of_indices before <rank>])\n",
    "    '''\n",
    "    if distance == \"euclidean\":\n",
    "        dist = ((emb_for_comparison-pred)**2).sum(axis=1)\n",
    "    elif distance == \"cosine\":\n",
    "        dist = 1 - (emb_for_comparison.dot(pred))/(np.linalg.norm(emb_for_comparison, axis=1)*np.linalg.norm(pred))\n",
    "\n",
    "    maxy = max(dist)\n",
    "\n",
    "    list_of_indices = []\n",
    "    for attempt in range(dist.shape[0]):\n",
    "        miny = dist.argmin()\n",
    "#         print(miny, correct_index, dist[correct_index], min(dist), maxy)\n",
    "        if dist[miny] == dist[correct_index]:\n",
    "#             print(i, attempt)\n",
    "            break\n",
    "        else:\n",
    "            list_of_indices.append(miny)\n",
    "            if k is not None and len(list_of_indices) == k:\n",
    "                return list_of_indices\n",
    "            dist[miny] = 100000\n",
    "    \n",
    "    # When the rank(correct_index) < k, then returns <rank, list>. So this extra condition - add some indices after rank(correct_index) to the list\n",
    "    if k is not None:\n",
    "        dist[miny] = 100000\n",
    "        for attempt in range(min(k, emb_for_comparison.shape[0]-1) - len(list_of_indices)):\n",
    "            miny = dist.argmin()\n",
    "            list_of_indices.append(miny)\n",
    "            dist[miny] = 100000\n",
    "        return list_of_indices\n",
    "    return attempt, list_of_indices\n",
    "\n",
    "def get_top_k_indices(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=1):\n",
    "    return get_ranking(pred, emb_for_comparison, correct_index, distance, k)\n",
    "    \n",
    "pred = model(torch.Tensor(X[int(main_df.shape[0]*0.8):]).to(device)).detach().cpu().numpy()\n",
    "l = []\n",
    "total = []\n",
    "for i in tqdm.tqdm(range(pred.shape[0])):\n",
    "    pred_for_i = pred[i]\n",
    "    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[int(main_df.shape[0]*0.8)+i]], correct_indices[int(main_df.shape[0]*0.8)+i]\n",
    "\n",
    "    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=\"euclidean\")\n",
    "    l.append(rank)\n",
    "    total.append(act_emb_for_i.shape[0])\n",
    "print(f\"{np.mean(l)}({np.mean(total)}) +- {np.std(l)}  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7213fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/mangye16/ReID-Survey\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: pytorch Variable, with shape [m, d]\n",
    "      y: pytorch Variable, with shape [n, d]\n",
    "    Returns:\n",
    "      dist: pytorch Variable, with shape [m, n]\n",
    "    \"\"\"\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n",
    "    dist = xx + yy\n",
    "    dist.addmm_(1, -2, x, y.t())\n",
    "    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "    return dist\n",
    "\n",
    "def cosine_dist(x, y):\n",
    "    xy = x.matmul(y.t())\n",
    "\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.linalg.norm(x, axis=1).expand(n, m).t()\n",
    "    yy = torch.linalg.norm(y, axis=1).expand(m, n)\n",
    "    \n",
    "    return 1 - xy / (xx*yy)\n",
    "\n",
    "\n",
    "def softmax_weights(dist, mask):\n",
    "    max_v = torch.max(dist * mask, dim=1, keepdim=True)[0]\n",
    "    diff = dist - max_v\n",
    "    Z = torch.sum(torch.exp(diff) * mask, dim=1, keepdim=True) + 1e-6 # avoid division by zero\n",
    "    W = torch.exp(diff) * mask / Z\n",
    "    return W\n",
    "\n",
    "class WeightedRegularizedTriplet(object):\n",
    "    def __init__(self, dist=\"euclidean\"):\n",
    "        self.ranking_loss = nn.SoftMarginLoss()\n",
    "        self.dist = dist\n",
    "\n",
    "    def __call__(self, global_feat, labels):\n",
    "        if self.dist==\"euclidean\":\n",
    "            dist_mat = euclidean_dist(global_feat, global_feat)\n",
    "        elif self.dist==\"cosine\":\n",
    "            dist_mat = cosine_dist(global_feat, global_feat) ####### NEEEDS TO BE CHANGED!!!!!!!!!!!\n",
    "\n",
    "        N = dist_mat.size(0)\n",
    "        # shape [N, N]\n",
    "        is_pos = labels.expand(N, N).eq(labels.expand(N, N).t()).float()\n",
    "        is_neg = labels.expand(N, N).ne(labels.expand(N, N).t()).float()\n",
    "\n",
    "        # `dist_ap` means distance(anchor, positive)\n",
    "        # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "        dist_ap = dist_mat * is_pos\n",
    "        dist_an = dist_mat * is_neg\n",
    "\n",
    "        weights_ap = softmax_weights(dist_ap, is_pos)\n",
    "        weights_an = softmax_weights(-dist_an, is_neg)\n",
    "        furthest_positive = torch.sum(dist_ap * weights_ap, dim=1)\n",
    "        closest_negative = torch.sum(dist_an * weights_an, dim=1)\n",
    "\n",
    "        y = furthest_positive.new().resize_as_(furthest_positive).fill_(1)\n",
    "        loss = self.ranking_loss(closest_negative - furthest_positive, y)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae378842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(X.shape[0]*0.8))\n",
    "test_idx = np.arange(int(X.shape[0]*0.8), X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09cc699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 16s, sys: 22.3 s, total: 14min 38s\n",
      "Wall time: 14min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "\n",
    "test_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"reactant\"]))).to(device)\n",
    "test_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"product\"]))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2011ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.GIN = torch.load(\"models/zinc2m_gin.pth\")\n",
    "        self.DENSE = torch.load(\"datasets/my_uspto/supervised_zinc_gin/mse_model.pth\")\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.GIN(x1, x1.node_feature.float())[\"graph_feature\"]\n",
    "        out2 = self.GIN(x2, x2.node_feature.float())[\"graph_feature\"]\n",
    "        \n",
    "        out = torch.concatenate([out1, out2], axis=1)\n",
    "        out = self.DENSE(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9fcd0",
   "metadata": {},
   "source": [
    "lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "for distance_metric, negative_method, topk, emb_model_update in itertools.product([\"euclidean\"], [\"all\"], [10, 5], [1, 2, 5]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    \n",
    "    model = PolicyNetwork().to(device)\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "    criterion = WeightedRegularizedTriplet()\n",
    "    \n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "    action_embeddings_norm = np.linalg.norm(action_embeddings, axis=1)\n",
    "    \n",
    "    metric_dict = {\"rank(cosine)\": [], \"rank(euclidean)\": [], \"rmse\": [], \"cos_dist\": []}\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "            outputs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size])\n",
    "\n",
    "            # Calc negatives\n",
    "            negatives = []\n",
    "            \n",
    "            for _i in range(outputs.shape[0]):\n",
    "                act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[train_idx[i+_i]]], correct_indices[train_idx[i+_i]]\n",
    "                curr_out = outputs[_i].detach().cpu().numpy()\n",
    "\n",
    "                if negative_method == \"applicable\":\n",
    "                    top = get_top_k_indices(curr_out, act_emb_for_i, correct_index, distance=distance_metric, k=50)\n",
    "                    negatives.append(act_emb_for_i[top])\n",
    "                \n",
    "                elif negative_method == \"all\":\n",
    "                    if distance_metric == \"euclidean\":\n",
    "                        dist = np.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                    elif distance_metric == \"cosine\":\n",
    "                        dist = (1 - action_embeddings.dot(curr_out)) / (action_embeddings_norm *np.linalg.norm(curr_out))\n",
    "                    sorted_idx = np.argsort(dist)[:topk] # get topk\n",
    "                    sorted_idx = sorted_idx[sorted_idx != correct_index] # Remove if correct index in list\n",
    "                    negatives.append(action_embeddings[sorted_idx])\n",
    "                        \n",
    "            negatives = torch.Tensor(np.concatenate(negatives, axis=0)).to(device)\n",
    "                                \n",
    "            # get targets\n",
    "            targets = torch.Tensor(get_action_embedding(embedding_model, main_df.iloc[i:i+batch_size][main_df.columns[1:-1]])).to(device)\n",
    "                                \n",
    "            # Calc loss\n",
    "            inputs = torch.concat([outputs, targets, negatives])\n",
    "            labels = torch.concat([torch.arange(outputs.shape[0]), torch.arange(targets.shape[0]), torch.full((negatives.shape[0],), -1)]).to(device)\n",
    "            loss = criterion(inputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print ('{:.6f}({})'.format(loss.item(), epoch), end='  ')\n",
    "        \n",
    "        # SWITCH INDENT HERE ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            margin_string = f\"# emb_model_update = {emb_model_update} | -ve_method = {negative_method} | dist_metric = {distance_metric} | topk = {topk} #\"\n",
    "            print(\"#\" * len(margin_string))\n",
    "            print(margin_string)\n",
    "            print(\"#\" * len(margin_string))\n",
    "\n",
    "            # Predictions and action component-wise loss\n",
    "            pred = model(test_reactants, test_products).detach().cpu().numpy() \n",
    "            true = get_action_embedding(embedding_model, main_df.iloc[test_idx][main_df.columns[1:-1]])\n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_dist\", \"rank(euclidean)\", \"rank(cosine)\"])\n",
    "\n",
    "            # Print Test metrics\n",
    "            metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean() )\n",
    "            metric_dict[\"cos_dist\"].append( ((pred*true).sum(axis=1) / np.linalg.norm(pred, axis=1) / np.linalg.norm(true, axis=1)).mean() )\n",
    "\n",
    "            # Print Test metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[test_idx[i]]], correct_indices[test_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=dist)\n",
    "                    l.append(rank)\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                metric_dict[f\"rank({dist})\"].append(np.mean(l))\n",
    "\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "            \n",
    "        # Update embedding model and action_embeddings\n",
    "        if epoch % emb_model_update == 0:\n",
    "            embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "            action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "            action_embeddings_norm = np.linalg.norm(action_embeddings, axis=1)\n",
    "            \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"rank\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(distance_metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # save everything\n",
    "    folder = f\"models/supervised/emb_model_update={emb_model_update}||-ve_method={negative_method}||dist_metric={distance_metric}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "    json.dump({\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"distance_metric\": distance_metric,\n",
    "        \"negative_method\": negative_method,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464d105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:14<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.939456(1)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  1 │ 5.40174 │   0.712225 │           95.1163 │        90.5212 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:14<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 95.11629416674396\n",
      "3.771772(2)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  2 │ 5.37406 │   0.723317 │            93.805 │        88.5706 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:12<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 93.80497078735046\n",
      "3.790295(3)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  3 │ 5.36645 │   0.727116 │           92.8755 │        87.6982 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:11<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 92.87554483909858\n",
      "3.850317(4)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  4 │ 5.32654 │     0.7308 │           93.7858 │        87.3741 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:10<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.254366(5)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  5 │ 5.35856 │   0.729853 │           91.4537 │        86.1973 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:10<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 91.45372345358435\n",
      "2.841396(6)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  6 │ 5.27396 │   0.736233 │           92.4302 │           86.3 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:08<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.641994(7)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  7 │ 5.26165 │   0.740818 │            91.224 │        85.6658 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 91.22396364648057\n",
      "5.712537(8)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  8 │ 5.29801 │   0.740434 │           92.0502 │        86.2231 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:01<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.446737(9)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│  9 │ 5.26701 │   0.744009 │           90.5809 │        84.2438 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [04:59<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 90.58086803301494\n",
      "4.568167(10)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │   rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│ 10 │  5.254 │   0.746956 │           89.9424 │        84.5942 │\n",
      "╘════╧════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:01<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 89.94240934804785\n",
      "3.987677(11)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│ 11 │ 5.23925 │   0.746372 │           91.2803 │        84.8132 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [04:59<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.273151(12)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│ 12 │ 5.28543 │   0.745857 │            92.276 │        85.8269 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:09<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.087873(13)  \n",
      "#################################################################################\n",
      "# emb_model_update = 1 | -ve_method = all | dist_metric = euclidean | topk = 10 #\n",
      "#################################################################################\n",
      "╒════╤═════════╤════════════╤═══════════════════╤════════════════╕\n",
      "│    │    rmse │   cos_dist │   rank(euclidean) │   rank(cosine) │\n",
      "╞════╪═════════╪════════════╪═══════════════════╪════════════════╡\n",
      "│ 13 │ 5.27949 │   0.747382 │           89.3641 │        83.3814 │\n",
      "╘════╧═════════╧════════════╧═══════════════════╧════════════════╛\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 699/699 [05:18<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL UPDATED! BEST RANK = 89.36409162570713\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "for distance_metric, negative_method, topk, emb_model_update in itertools.product([\"euclidean\"], [\"all\"], [10], [1, 2, 5]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    \n",
    "    best_rank = 10000\n",
    "    best_model = None\n",
    "    \n",
    "    model = PolicyNetwork().to(device)\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "    criterion = WeightedRegularizedTriplet()\n",
    "    \n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "    action_embeddings_norm = np.linalg.norm(action_embeddings, axis=1)\n",
    "    \n",
    "    metric_dict = {\"rank(cosine)\": [], \"rank(euclidean)\": [], \"rmse\": [], \"cos_dist\": []}\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "            outputs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size])\n",
    "\n",
    "            # Calc negatives\n",
    "            negatives = []\n",
    "            \n",
    "            for _i in range(outputs.shape[0]):\n",
    "                act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[train_idx[i+_i]]], correct_indices[train_idx[i+_i]]\n",
    "                curr_out = outputs[_i].detach().cpu().numpy()\n",
    "\n",
    "                if negative_method == \"applicable\":\n",
    "                    top = get_top_k_indices(curr_out, act_emb_for_i, correct_index, distance=distance_metric, k=50)\n",
    "                    negatives.append(act_emb_for_i[top])\n",
    "                \n",
    "                elif negative_method == \"all\":\n",
    "                    if distance_metric == \"euclidean\":\n",
    "                        dist = np.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                    elif distance_metric == \"cosine\":\n",
    "                        dist = (1 - action_embeddings.dot(curr_out)) / (action_embeddings_norm *np.linalg.norm(curr_out))\n",
    "                    sorted_idx = np.argsort(dist)[:topk] # get topk\n",
    "                    sorted_idx = sorted_idx[sorted_idx != correct_index] # Remove if correct index in list\n",
    "                    negatives.append(action_embeddings[sorted_idx])\n",
    "                        \n",
    "            negatives = torch.Tensor(np.concatenate(negatives, axis=0)).to(device)\n",
    "                                \n",
    "            # get targets\n",
    "            targets = torch.Tensor(get_action_embedding(embedding_model, main_df.iloc[i:i+batch_size][main_df.columns[1:-1]])).to(device)\n",
    "                                \n",
    "            # Calc loss\n",
    "            inputs = torch.concat([outputs, targets, negatives])\n",
    "            labels = torch.concat([torch.arange(outputs.shape[0]), torch.arange(targets.shape[0]), torch.full((negatives.shape[0],), -1)]).to(device)\n",
    "            loss = criterion(inputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print ('{:.6f}({})'.format(loss.item(), epoch), end='  ')\n",
    "        \n",
    "        # SWITCH INDENT HERE ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            margin_string = f\"# emb_model_update = {emb_model_update} | -ve_method = {negative_method} | dist_metric = {distance_metric} | topk = {topk} #\"\n",
    "            print(\"#\" * len(margin_string))\n",
    "            print(margin_string)\n",
    "            print(\"#\" * len(margin_string))\n",
    "\n",
    "            # Predictions and action component-wise loss\n",
    "            pred = model(test_reactants, test_products).detach().cpu().numpy() \n",
    "            true = get_action_embedding(embedding_model, main_df.iloc[test_idx][main_df.columns[1:-1]])\n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_dist\", \"rank(euclidean)\", \"rank(cosine)\"])\n",
    "\n",
    "            # Print Test metrics\n",
    "            metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean() )\n",
    "            metric_dict[\"cos_dist\"].append( ((pred*true).sum(axis=1) / np.linalg.norm(pred, axis=1) / np.linalg.norm(true, axis=1)).mean() )\n",
    "\n",
    "            # Print Test metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[test_idx[i]]], correct_indices[test_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=dist)\n",
    "                    l.append(rank)\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                metric_dict[f\"rank({dist})\"].append(np.mean(l))\n",
    "\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "            \n",
    "        # Update embedding model and action_embeddings\n",
    "        if epoch % emb_model_update == 0:\n",
    "            embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "            action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "            action_embeddings_norm = np.linalg.norm(action_embeddings, axis=1)\n",
    "        \n",
    "        # Update best model\n",
    "        if metric_dict[\"rank(euclidean)\"][-1] < best_rank:\n",
    "            best_rank = metric_dict[\"rank(euclidean)\"][-1]\n",
    "            best_model = type(model)()\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "            print(f\"BEST MODEL UPDATED! BEST RANK = {best_rank}\")\n",
    "            \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"rank\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(distance_metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # save everything\n",
    "    folder = f\"models/supervised/5step/emb_model_update={emb_model_update}||-ve_method={negative_method}||dist_metric={distance_metric}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "    json.dump({\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"distance_metric\": distance_metric,\n",
    "        \"negative_method\": negative_method,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_rank\": best_rank\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d11ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
