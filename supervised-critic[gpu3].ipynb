{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run supervised_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ee07c",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536ae7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_mols = pickle.load(open(\"datasets/my_uspto/unique_start_mols.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bdda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████▉                              | 46374/100000 [01:31<01:27, 612.67it/s]"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "N = 100000\n",
    "steps = 2\n",
    "\n",
    "df_list = []\n",
    "final_shape = 0\n",
    "smiles_per_random_sample = 1000\n",
    "pool_chunk_size = 10\n",
    "\n",
    "# Create dataset for multi-step pred\n",
    "with Pool(30) as p, tqdm.tqdm(total=N) as pbar:\n",
    "    while final_shape < N:\n",
    "        smiles = np.random.choice(start_mols, size=(smiles_per_random_sample,))\n",
    "\n",
    "        for new_df in p.imap_unordered(functools.partial(generate_train_data, steps=steps), smiles, chunksize=10):\n",
    "            df_list.append(new_df)\n",
    "            final_shape += new_df.shape[0]\n",
    "            \n",
    "        pbar.update(final_shape - pbar.n)\n",
    "\n",
    "main_df = pd.concat(df_list)\n",
    "del df_list\n",
    "print(main_df.shape)\n",
    "\n",
    "# randomize\n",
    "main_df = pd.concat([main_df[:int(main_df.shape[0]*0.8)].sample(frac=1), main_df[int(main_df.shape[0]*0.8):].sample(frac=1)])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58b5a",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb759a",
   "metadata": {},
   "source": [
    "# Helper stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "action_dataset = pd.read_csv(\"datasets/my_uspto/action_dataset-filtered.csv\", index_col=0)\n",
    "action_dataset = action_dataset.loc[action_dataset[\"action_tested\"] & action_dataset[\"action_works\"]]\n",
    "action_dataset = action_dataset[[\"rsub\", \"rcen\", \"rsig\", \"rbond\", \"psub\", \"pcen\", \"psig\", \"pbond\"]]\n",
    "print(action_dataset.shape)\n",
    "\n",
    "action_rsigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"rsig\"])))\n",
    "action_psigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"psig\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_applicable_indices = []\n",
    "correct_action_dataset_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, main_df.iterrows()), total=main_df.shape[0]):\n",
    "with Pool(20) as p:\n",
    "    for indices_used_for_data, correct_app_idx, correct_act_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, main_df.iterrows(), chunksize=50), total=main_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_applicable_indices.append(correct_app_idx)\n",
    "        correct_action_dataset_indices.append(correct_act_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22704c57",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(main_df.shape[0]*0.8))\n",
    "test_idx = np.arange(int(main_df.shape[0]*0.8), main_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cc5e0",
   "metadata": {},
   "source": [
    "train_idx = torch.arange(0, int(main_df.shape[0]*0.8))[:500]\n",
    "test_idx = torch.arange(int(main_df.shape[0]*0.8), main_df.shape[0])[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "train_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"rsig\"]))).to(device)\n",
    "train_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"psig\"]))).to(device)\n",
    "\n",
    "test_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"reactant\"]))).to(device)\n",
    "test_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"product\"]))).to(device)\n",
    "test_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"rsig\"]))).to(device)\n",
    "test_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"psig\"]))).to(device)\n",
    "\n",
    "print(train_reactants.batch_size, train_products.batch_size, train_rsigs.batch_size, train_psigs.batch_size)\n",
    "print(test_reactants.batch_size, test_products.batch_size, test_rsigs.batch_size, test_psigs.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571bee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "for topk, emb_model_update in itertools.product([10], [1]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "\n",
    "    # Model inits\n",
    "    model = CriticNetwork().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "    loss_criterion = nn.MSELoss()\n",
    "    \n",
    "    # Embeddings init\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "    action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "    \n",
    "    # Some helper inits\n",
    "    best_metric = -100\n",
    "    best_model = None\n",
    "    \n",
    "    metric_dict = {\"GT_acc\": [], \"GT_rec\": [], \"GT_prec\": [], \"GT_f1\": [], \n",
    "                    \"others_acc\": [], \"others_rec\": [], \"others_prec\": [], \"others_f1\": [], \n",
    "                    \"mean_acc\": [], \"mean_rec\": [], \"mean_prec\": [], \"mean_f1\": [],  \"time(epoch_start-now)\": []}\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "#             qs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "            curr_shape = min(i+batch_size, train_reactants.batch_size) - i\n",
    "\n",
    "            # Calc negatives\n",
    "            negative_indices = []\n",
    "            \n",
    "            for _i in range(curr_shape):\n",
    "                correct_action_dataset_index = correct_action_dataset_indices[train_idx[i+_i]]\n",
    "                curr_out = action_embeddings[correct_action_dataset_index]\n",
    "                dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                sorted_idx = torch.argsort(dist)[:topk] # get topk\n",
    "                sorted_idx = sorted_idx[sorted_idx != correct_action_dataset_index] # Remove if correct index in list\n",
    "                negative_indices.append(sorted_idx)\n",
    "                \n",
    "            # critic update\n",
    "            batch_reactants = train_reactants[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(curr_shape)], [])]\n",
    "            batch_products = train_products[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(curr_shape)], [])]\n",
    "            batch_rsigs = action_rsigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(curr_shape)], [])]\n",
    "            batch_psigs = action_psigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(curr_shape)], [])]\n",
    "            batch_q_targets = torch.Tensor(sum([[1] + [0] * negative_indices[_i].shape[0] for _i in range(curr_shape)], [])).view(-1, 1)\n",
    "\n",
    "            \n",
    "            qs = model(batch_reactants.to(device), batch_products.to(device), batch_rsigs.to(device), batch_psigs.to(device))\n",
    "            loss = loss_criterion(qs, batch_q_targets.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Emptry any cache (free GPU memory)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print (f'Epoch {epoch}/{epochs}. Batch {i}/{train_reactants.batch_size - batch_size}. Train loss = {loss.item():.6f}')#, end='\\r')\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            # Update embedding model and action_embeddings\n",
    "            if epoch % emb_model_update == 0:\n",
    "                embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "                action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "                action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "\n",
    "            # Predict for GT\n",
    "            GT_pred_qs = (model(test_reactants, test_products, test_rsigs, test_psigs).detach().cpu().numpy() > 0.5).astype(int)\n",
    "            GT_true_qs = np.ones_like(GT_pred_qs)\n",
    "\n",
    "            # Pred for others\n",
    "            negative_indices = []\n",
    "\n",
    "            for i in test_idx:\n",
    "                correct_action_dataset_index = correct_action_dataset_indices[i]\n",
    "                curr_out = action_embeddings[correct_action_dataset_index]\n",
    "                dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "\n",
    "                # Get the closest that is not GT\n",
    "                sorted_idx = torch.argsort(dist)[:2]\n",
    "                sorted_idx = sorted_idx[sorted_idx != correct_action_dataset_index] # Remove if correct index in list\n",
    "                sorted_idx = sorted_idx[:1]\n",
    "                negative_indices.append(sorted_idx)\n",
    "\n",
    "            # critic update\n",
    "            test_batch_reactants = test_reactants[sum([[i]*negative_indices[i].shape[0] for i in range(test_idx.shape[0])], [])].to(device)\n",
    "            test_batch_products = test_products[sum([[i]*negative_indices[i].shape[0] for i in range(test_idx.shape[0])], [])].to(device)\n",
    "            test_batch_rsigs = action_rsigs[torch.concatenate(negative_indices)].to(device)\n",
    "            test_batch_psigs = action_psigs[torch.concatenate(negative_indices)].to(device)\n",
    "\n",
    "            others_pred_qs = (model(test_batch_reactants, test_batch_products, test_batch_rsigs, test_batch_psigs).detach().cpu().numpy() > 0.5).astype(int)\n",
    "            others_true_qs = np.zeros_like(others_pred_qs)\n",
    "\n",
    "            # Update metrics (with inverted labels -- sklearn considers 0 as true class in confusion matrix)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(GT_true_qs, GT_pred_qs), precision_recall_fscore_support(GT_true_qs, GT_pred_qs, average=\"binary\")\n",
    "            metric_dict[\"GT_acc\"].append(acc); metric_dict[\"GT_rec\"].append(rec); metric_dict[\"GT_prec\"].append(prec); metric_dict[\"GT_f1\"].append(f1)\n",
    "\n",
    "            # 1-others in prec_rec_f1 because sklearn wants true class as 1 and others has true class 0 (only for the sake of metric scores)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(others_true_qs, others_pred_qs), precision_recall_fscore_support(1-others_true_qs, 1-others_pred_qs, average=\"binary\") \n",
    "            metric_dict[\"others_acc\"].append(acc); metric_dict[\"others_rec\"].append(rec); metric_dict[\"others_prec\"].append(prec); metric_dict[\"others_f1\"].append(f1)\n",
    "\n",
    "            mean_pred_qs = np.concatenate([GT_pred_qs, others_pred_qs], axis=0)\n",
    "            mean_true_qs = np.concatenate([GT_true_qs, others_true_qs], axis=0)\n",
    "            acc, (prec, rec, f1, _) = accuracy_score(mean_true_qs, mean_pred_qs), precision_recall_fscore_support(mean_true_qs, mean_pred_qs, average=\"binary\")\n",
    "            metric_dict[\"mean_acc\"].append(acc); metric_dict[\"mean_rec\"].append(rec); metric_dict[\"mean_prec\"].append(prec); metric_dict[\"mean_f1\"].append(f1)\n",
    "\n",
    "            # Print\n",
    "            metric_df = pd.DataFrame(columns=[\"GT_acc\", \"GT_rec\", \"GT_prec\", \"GT_f1\", \"others_acc\", \"others_rec\", \"others_prec\", \"others_f1\", \n",
    "                                              \"mean_acc\", \"mean_rec\", \"mean_prec\", \"mean_f1\",  \"time(epoch_start-now)\"])\n",
    "\n",
    "            metric_dict[\"time(epoch_start-now)\"].append(f\"{(time.time()-start_time)/60:.2f} min\")\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "\n",
    "            \n",
    "\n",
    "        # Update best model (with GT f1 - we want critic for best GT)\n",
    "        metric_for_best_model = \"GT_f1\"\n",
    "        curr_metric = metric_dict[metric_for_best_model][-1]\n",
    "        if curr_metric > best_metric:\n",
    "            best_metric = curr_metric\n",
    "            best_model = type(model)()\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "            print(f\"BEST MODEL UPDATED! BEST {metric_for_best_model} = {best_metric}\")\n",
    "\n",
    "    # save everything\n",
    "    folder = f\"models/supervised/critic/emb_model_update={emb_model_update}||steps={steps}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "\n",
    "    # Save plots\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    line_style = {\"GT\": \"-\", \"others\": \":\", \"mean\": \"--\"}\n",
    "    for metric in filter(lambda x: \"time\" not in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[metric], label=metric, linestyle=line_style[metric.split(\"_\")[0]])\n",
    "    plt.title(f\"steps={steps}\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"metrics\")\n",
    "    plt.legend()\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "\n",
    "    json.dump({\n",
    "        \"steps(trajectory length)\": steps,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        f\"best_{metric_for_best_model}\": best_metric,\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))\n",
    "    print(\"Saved model at\", folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
