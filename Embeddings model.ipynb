{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71214824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:23:50.678863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-27 15:23:50.818617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-27 15:23:50.818636: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-27 15:23:50.840029: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-27 15:23:51.681698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-27 15:23:51.681767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-27 15:23:51.681775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "import torch\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85fe50",
   "metadata": {},
   "source": [
    "# Train a embedding model on ChemBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df91be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.16 ms, sys: 9 Âµs, total: 8.17 ms\n",
      "Wall time: 7.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load raw dataset\n",
    "chembl_tasks, datasets, transformers = dc.molnet.load_chembl(shard_size=2000, featurizer=\"raw\", set=\"5thresh\", splitter=\"random\")\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e7faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 ms, sys: 41 ms, total: 78.5 ms\n",
      "Wall time: 77.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Featurize the input\n",
    "f = dc.feat.MolGraphConvFeaturizer(use_edges=True, use_partial_charge=True)\n",
    "y = train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a99814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNN(\n",
      "  (model): MPNNPredictor(\n",
      "    (gnn): MPNNGNN(\n",
      "      (project_node_feats): Sequential(\n",
      "        (0): Linear(in_features=31, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (gnn_layer): NNConv(\n",
      "        (edge_func): Sequential(\n",
      "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=4096, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (gru): GRU(64, 64)\n",
      "    )\n",
      "    (readout): Set2Set(\n",
      "      n_iters=6\n",
      "      (lstm): LSTM(128, 64, num_layers=3)\n",
      "    )\n",
      "    (predict): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=691, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhor/miniconda3/envs/de_nono/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 14min 47s, sys: 20min 27s, total: 2h 35min 14s\n",
      "Wall time: 29min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8006814956665039"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the MPNN model\n",
    "model = dc.models.torch_models.MPNNModel(len(chembl_tasks), number_atom_features=31, number_bond_features=11)\n",
    "\n",
    "print(model.model)\n",
    "\n",
    "model.fit(dc.data.NumpyDataset(f.featurize(train_dataset.X), y)) # On original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e944fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean-rms_score': 0.29822712602210644},\n",
       " {'mean-rms_score': 0.2937193354348491},\n",
       " {'mean-rms_score': 0.2922992680009213})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see some scores (rmse)\n",
    "avg_rms = dc.metrics.Metric(dc.metrics.rms_score, np.mean)\n",
    "model.evaluate(dc.data.NumpyDataset(f.featurize(train_dataset.X), y), [avg_rms], transformers), model.evaluate(dc.data.NumpyDataset(f.featurize(valid_dataset.X), valid_dataset.y), [avg_rms], transformers), model.evaluate(dc.data.NumpyDataset(f.featurize(test_dataset.X), test_dataset.y), [avg_rms], transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041d3c6",
   "metadata": {},
   "source": [
    "# Output of 1 sample for qualitative comparision\n",
    "list(zip(train_dataset.y[:1].flatten(), model.predict(dc.data.NumpyDataset(x[:1], y[:1])).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a629c",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "# Train the MPNN model\n",
    "model = dc.models.torch_models.MPNNModel(len(chembl_tasks), number_atom_features=31, number_bond_features=11)\n",
    "\n",
    "print(model.model)\n",
    "\n",
    "# There are single atom molecules in the actions - For these, featurizer does not work - so adding H's so each atom has at least some neighbors\n",
    "X = []\n",
    "for mol in tqdm.tqdm(train_dataset.X):\n",
    "    X.append(Chem.AddHs(mol))\n",
    "X = np.array(X)\n",
    "x = f.featurize(X)\n",
    "\n",
    "# train\n",
    "model.fit(dc.data.NumpyDataset(x, y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6718a",
   "metadata": {},
   "source": [
    "# Lets see some scores (rmse)\n",
    "avg_rms = dc.metrics.Metric(dc.metrics.rms_score, np.mean)\n",
    "model.evaluate(dc.data.NumpyDataset(x, y), [avg_rms], transformers), \\\n",
    "    model.evaluate(dc.data.NumpyDataset(f.featurize(np.vectorize(Chem.AddHs)(valid_dataset.X)), valid_dataset.y), [avg_rms], transformers), \\\n",
    "    model.evaluate(dc.data.NumpyDataset(f.featurize(np.vectorize(Chem.AddHs)(test_dataset.X)), test_dataset.y), [avg_rms], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a254d3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.007236693326090918, 0.046405684),\n",
       " (-0.04238371855537214, 0.03333094),\n",
       " (0.0, 0.0042083673),\n",
       " (0.0, 0.0054020616),\n",
       " (-0.027899843079487056, -0.1623196),\n",
       " (-0.025025194419930924, 0.087228),\n",
       " (-0.01908282090230921, -0.12722534),\n",
       " (-0.02155178296682597, 0.17189683),\n",
       " (0.0, 0.00073351525),\n",
       " (-0.022514736706494138, 0.0722889),\n",
       " (-0.023869481191052172, -0.18381195),\n",
       " (0.0, 0.0032516294),\n",
       " (0.0, 0.00078660273),\n",
       " (-0.017423504840988296, -0.01792328),\n",
       " (-0.00723669332609096, -0.0012517273),\n",
       " (-0.025991172597553413, 0.1282811),\n",
       " (0.0, 0.0006487537),\n",
       " (0.0, 0.005099844),\n",
       " (0.0, 0.00057454384),\n",
       " (-0.010232547811979919, 0.049526636),\n",
       " (-0.01601282273079471, -0.025450686),\n",
       " (-0.010137734473236647, 0.33755314),\n",
       " (0.0, -0.003937754),\n",
       " (-0.06908539966106848, 0.17600611),\n",
       " (-0.0846528929503079, 0.16919325),\n",
       " (-0.014448120136706365, 0.5802632),\n",
       " (-0.014447497539225454, -0.061601836),\n",
       " (-0.007236693326090872, -0.11938442),\n",
       " (-0.07556022955680562, -0.14868255),\n",
       " (-0.07963641257843566, 0.052914195),\n",
       " (-0.0124839641132135, -0.05818941),\n",
       " (-0.050075517533690106, 0.5524479),\n",
       " (-0.09037713892068028, -0.10310587),\n",
       " (0.0, -0.0035598893),\n",
       " (-0.05692884268673976, 0.4905487),\n",
       " (0.0, -0.00139364),\n",
       " (-0.048967922164107745, -0.14229517),\n",
       " (-0.12811777183349055, 0.7454853),\n",
       " (-0.13386908053193228, -0.31372672),\n",
       " (-0.05635570430881696, 0.6339066),\n",
       " (-0.07228245725391363, -0.19966781),\n",
       " (-0.007236693326090975, 0.059757162),\n",
       " (-0.07192979289505493, -0.049975447),\n",
       " (-0.0784661328267296, 0.11191478),\n",
       " (-0.010149328914848385, -0.11877502),\n",
       " (0.0, -0.0030722842),\n",
       " (-0.01846374965422405, 0.11872947),\n",
       " (-0.07934138105200847, 0.10319915),\n",
       " (-0.1648427426976631, 0.66937965),\n",
       " (-0.11098899666123031, -0.046832107),\n",
       " (-0.0870833617450299, 0.008630633),\n",
       " (-0.07326153679610367, 0.05922894),\n",
       " (-0.05759392461231801, -0.019483803),\n",
       " (-0.03744373910652677, -0.25229314),\n",
       " (0.0, -0.0061141783),\n",
       " (-0.059131828388452365, 0.69656),\n",
       " (-0.07204864947549112, 0.06580805),\n",
       " (0.0, -0.0018149354),\n",
       " (-0.10559874899648831, -0.27694812),\n",
       " (-0.047266200850689756, -0.10112199),\n",
       " (-0.03768088643839103, -0.18187346),\n",
       " (-0.04256430709499034, 0.22308126),\n",
       " (-0.007236693326090876, 0.05057729),\n",
       " (-0.04391844937727215, -0.00637985),\n",
       " (-0.015855341294117045, 0.18110478),\n",
       " (-0.09744083616858995, -0.61084735),\n",
       " (-0.09639272984728495, 0.050722957),\n",
       " (-0.08670387172291281, -0.30446824),\n",
       " (-0.10466870924834144, -0.081782445),\n",
       " (-0.06940627220270532, -0.10856269),\n",
       " (0.0, -0.015625509),\n",
       " (-0.05705944166549738, 0.1743055),\n",
       " (0.0, 0.0055844258),\n",
       " (-0.12017167718184137, -0.0030613244),\n",
       " (-0.11808378559176275, -0.09846693),\n",
       " (-0.1273041358927527, 0.45301998),\n",
       " (-0.053222800303202394, -0.012215659),\n",
       " (-0.09684034955884349, -0.11145282),\n",
       " (-0.009847796261183778, 0.25783807),\n",
       " (-0.015917802897810703, -0.07313664),\n",
       " (-0.016058525572090438, -0.07122757),\n",
       " (-0.016758958736318774, 0.043928254),\n",
       " (-0.007236693326091012, 0.023024976),\n",
       " (-0.08288595553445499, -0.4509685),\n",
       " (-0.05303299103488958, 0.31107283),\n",
       " (-0.06958739843100692, -0.10050713),\n",
       " (-0.06795650408746487, 0.06724716),\n",
       " (-0.007236693326090921, -0.050757565),\n",
       " (-0.027500431714269493, 0.08965333),\n",
       " (-0.11594715700535163, -0.12853697),\n",
       " (-0.024942490637672256, 0.20003629),\n",
       " (-0.09987471142758221, -0.53065526),\n",
       " (-0.05912473190391463, 0.022075593),\n",
       " (-0.05661550555975653, 0.032450095),\n",
       " (-0.10833717429733682, -0.29819077),\n",
       " (-0.01023185901533076, -0.032220356),\n",
       " (-0.038069866208415216, -0.024608359),\n",
       " (-0.09316872695347743, 0.27250612),\n",
       " (-0.03506940232962803, 0.2612931),\n",
       " (-0.007236693326090928, 0.016706893),\n",
       " (-0.038454652064908036, -0.24862592),\n",
       " (0.0, 0.0040679406),\n",
       " (0.0, 0.004133543),\n",
       " (-0.07280252238291204, 0.21559788),\n",
       " (-0.133472068123536, -0.20524904),\n",
       " (-0.025496301285495446, -0.07077907),\n",
       " (-0.07037874158596141, 0.1836202),\n",
       " (0.0, -0.005399376),\n",
       " (-0.08592843324899442, -0.03540898),\n",
       " (-0.09704353541355061, -0.043127134),\n",
       " (-0.09701355717075456, 0.23694958),\n",
       " (-0.08003708617842606, -0.060725525),\n",
       " (-0.101034203680766, -0.42411056),\n",
       " (-0.11378969169972068, -0.12064853),\n",
       " (-0.06652100325258688, 0.14936908),\n",
       " (-0.040547408023909305, -0.13027944),\n",
       " (-0.07187746409038173, 0.108445965),\n",
       " (-0.31329722332435195, -0.6153642),\n",
       " (-0.10066416011053547, -0.04605564),\n",
       " (-0.06802720294056012, 0.15863952),\n",
       " (0.0, -0.0013376162),\n",
       " (-0.03051529312538934, 0.10648919),\n",
       " (-0.09682368547344745, 0.22620307),\n",
       " (-0.012436000954547005, 0.07240878),\n",
       " (-0.00723669332609094, -0.005827684),\n",
       " (-0.03213712194981028, 0.13987315),\n",
       " (-0.0852087150739927, -0.66980404),\n",
       " (0.0, -0.003973519),\n",
       " (0.0, -0.0025906381),\n",
       " (-0.10653164522875147, -0.17015994),\n",
       " (-0.08436277262955731, -0.6657534),\n",
       " (-0.2146546181830595, -0.2053182),\n",
       " (0.0, 0.001952216),\n",
       " (-0.10334710904996557, -0.41529548),\n",
       " (-0.11793153194771747, -0.08450385),\n",
       " (-0.057947749442926175, 0.016960256),\n",
       " (-0.11530689029150992, -0.101667784),\n",
       " (-0.2532040667467628, 0.0033562034),\n",
       " (-0.010139199052964589, 0.041908536),\n",
       " (-0.10015325783888364, -0.21130928),\n",
       " (-0.07816783009446815, 0.22497746),\n",
       " (-0.14290408671407717, -0.16395915),\n",
       " (-0.1234800067261821, -0.49080223),\n",
       " (0.0, 0.00191628),\n",
       " (-0.030903058656123444, 0.0793041),\n",
       " (-0.051663675648900856, -0.21605879),\n",
       " (-0.23473135088368532, 0.02534666),\n",
       " (-0.1297634072682055, -0.12591064),\n",
       " (-0.2148499191854869, -0.26072925),\n",
       " (-0.04114580142574111, -0.14962845),\n",
       " (-0.17559889344159965, -0.23006353),\n",
       " (-0.2504502614851349, -0.20591263),\n",
       " (-0.03116467630965942, -0.037477545),\n",
       " (-0.012431064144057641, -0.07554755),\n",
       " (-0.06796584779593912, 1.1590227),\n",
       " (-0.06610269247713055, -0.018151231),\n",
       " (-0.2787520726447788, 0.025429107),\n",
       " (-0.039301833854912274, 0.5857219),\n",
       " (-0.010229917067397232, 0.019462712),\n",
       " (-0.1443277518095971, -0.010652117),\n",
       " (-0.05741148965488116, -0.072592594),\n",
       " (-0.06353038577948508, 0.09409382),\n",
       " (-0.031210317409512287, -0.28525728),\n",
       " (-0.030561308569709948, -0.097933695),\n",
       " (-0.09628119266402468, -0.10294254),\n",
       " (-0.03748565155232652, 0.6116459),\n",
       " (-0.1347519683592777, 0.037250727),\n",
       " (-0.1447048045402907, -0.41093794),\n",
       " (-0.03739556261089198, -0.05560717),\n",
       " (-0.02580024673466471, 0.025502667),\n",
       " (-0.2454497839120591, -0.054337323),\n",
       " (-0.07361733200064706, 4.1490374),\n",
       " (-0.023935480561418872, -0.08782593),\n",
       " (-0.04149955585706414, -0.11734693),\n",
       " (-0.2085481040787081, -0.26351234),\n",
       " (-0.03360527039130961, 0.016184866),\n",
       " (-0.12699534707451288, 0.153404),\n",
       " (-0.24141073267932145, 0.0003440082),\n",
       " (0.0, 0.0029510143),\n",
       " (-0.1099641732375204, -0.101402506),\n",
       " (-0.007236693326090919, -0.098488554),\n",
       " (-0.02265084242236548, 0.12750262),\n",
       " (0.0, -0.008071111),\n",
       " (-0.02274423758756745, 0.06782385),\n",
       " (-0.01249103660797683, 0.16186346),\n",
       " (-0.2426736903637389, -0.06727801),\n",
       " (-0.010217167702304736, -0.122667596),\n",
       " (-0.23094441324408158, 0.017784644),\n",
       " (-0.12471900083536432, 0.058484364),\n",
       " (-0.04188050078534251, 0.1870385),\n",
       " (-0.032807952362334275, -0.09092177),\n",
       " (-0.2111396987208347, -0.30802444),\n",
       " (-0.04304422069978636, -0.0622078),\n",
       " (-0.06272692987064517, -0.26112908),\n",
       " (-0.011661648749297553, -0.053376418),\n",
       " (-0.010233375889043822, -0.06239434),\n",
       " (-0.06902262228522651, 0.051272158),\n",
       " (-0.12612620079135028, 0.07573007),\n",
       " (-0.014104069961125024, 0.032008328),\n",
       " (-0.07072279573317553, -0.564829),\n",
       " (-0.010063706295609263, -0.110833466),\n",
       " (-0.10467079538183874, -0.09208351),\n",
       " (0.0, -0.003429953),\n",
       " (-0.09925169701283645, -0.13533679),\n",
       " (-0.07354841563083893, -0.53110206),\n",
       " (-0.007236693326090946, -0.0076616034),\n",
       " (-0.026023673740560024, 0.09948239),\n",
       " (-0.0691263837934536, -0.1425146),\n",
       " (-0.0101974759558139, -0.16580038),\n",
       " (-0.04401202946554694, -0.5059332),\n",
       " (-0.04110252688168803, -0.17209962),\n",
       " (-0.0501950842908587, 0.7208319),\n",
       " (-0.04543686728260593, 0.6198083),\n",
       " (-0.07259080559602701, 0.043424662),\n",
       " (-0.027173933818924, -0.038068954),\n",
       " (-0.04719662995600813, -0.024529397),\n",
       " (-0.25325263469789466, -0.20738171),\n",
       " (0.0, -0.006311301),\n",
       " (20.701738240523117, 0.705349),\n",
       " (-0.04279819625180962, 0.15580395),\n",
       " (-0.11279098672130146, -0.0976233),\n",
       " (-0.02661422474502874, 0.11125058),\n",
       " (-0.0072366933260909014, -0.068705715),\n",
       " (-0.07691963728707463, -0.11312068),\n",
       " (-0.17602166225756213, -0.13316566),\n",
       " (-0.23583750814750346, -0.26140308),\n",
       " (-0.061686803510813765, 0.5377065),\n",
       " (-0.033857205603816165, -0.2043783),\n",
       " (-0.007236693326090968, -0.04588984),\n",
       " (-0.007236693326090944, 0.045020983),\n",
       " (-0.038243731800876764, -0.14039835),\n",
       " (-0.09855743900571126, 0.23218063),\n",
       " (16.709540320456792, 0.68204015),\n",
       " (-0.1510246821461061, -0.23624957),\n",
       " (-0.012498310693518092, 0.31584638),\n",
       " (-0.05800974032606279, 0.17326353),\n",
       " (-0.07084911930616443, 0.050100595),\n",
       " (-0.3126814709552521, -0.60872525),\n",
       " (0.0, 0.0012703983),\n",
       " (-0.014416725456955323, -0.053547863),\n",
       " (-0.06329317236462673, -0.13971621),\n",
       " (-0.03517272454654647, -0.2292924),\n",
       " (-0.06792759168643409, 0.0029581934),\n",
       " (-0.139851224938268, -0.081128746),\n",
       " (-0.05928044665349481, -0.042653486),\n",
       " (-0.04981531751804583, -0.4235636),\n",
       " (-0.0072366933260909405, 0.034426525),\n",
       " (-0.09279104833148383, 0.0963721),\n",
       " (-0.147102748163806, -0.6962913),\n",
       " (-0.1411873979048567, 0.40357792),\n",
       " (-0.010120073875024106, 0.04097737),\n",
       " (-0.04827029703011274, 0.12658228),\n",
       " (-0.16739770724957242, 0.4647103),\n",
       " (-0.06980740043192588, 0.34226578),\n",
       " (-0.09701311641228594, -0.5442018),\n",
       " (-0.1388927002499195, -0.07112159),\n",
       " (0.0, -0.0011202195),\n",
       " (-0.012502870368809298, -0.074039176),\n",
       " (-0.015895031547704157, -0.03543553),\n",
       " (-0.07950933282080815, 0.17951298),\n",
       " (-0.05658594018107908, -0.020828791),\n",
       " (-0.08075883297950195, -0.09489601),\n",
       " (-0.018848989878337274, -0.07771602),\n",
       " (-0.04601691440612372, -0.022337377),\n",
       " (0.0, -0.0029883496),\n",
       " (0.0, 0.002924866),\n",
       " (0.0, 0.0034850708),\n",
       " (-0.025685076118102668, -0.06910637),\n",
       " (-0.021519256277802802, -0.27498698),\n",
       " (-0.1769693693439524, -0.022915011),\n",
       " (-0.13602856955005255, 1.8926761),\n",
       " (-0.040298482215983214, 0.13945568),\n",
       " (-0.039309472206576435, -0.03821723),\n",
       " (-0.04885937582964456, 0.052389458),\n",
       " (-0.0521875132873586, -0.08976014),\n",
       " (-0.043593584565383765, 0.104775704),\n",
       " (-0.1229128699289683, 1.6482812),\n",
       " (-0.013871678348819087, -0.05507248),\n",
       " (-0.11577636785088688, -0.22298455),\n",
       " (-0.11884692468657033, -0.029590204),\n",
       " (-0.07237663024736184, -0.10728049),\n",
       " (-0.017656044683588955, -0.1469953),\n",
       " (-0.017521613740278885, 0.050634883),\n",
       " (-0.07021813710521987, 0.07056772),\n",
       " (-0.025231882449627645, 0.22606748),\n",
       " (-0.04640625568881235, -0.015619881),\n",
       " (-0.03502241806515848, -0.12783147),\n",
       " (-0.02267743364221548, 0.13465774),\n",
       " (-0.08235832720687229, -0.08611996),\n",
       " (-0.025456981672350075, -0.13486551),\n",
       " (-0.06423503380502879, -0.19688413),\n",
       " (-0.060014260661260324, -0.048334405),\n",
       " (-0.021523170479687256, -0.029149938),\n",
       " (-0.01900301794944125, 0.073906444),\n",
       " (-0.058369472385285545, -0.15302728),\n",
       " (-0.15672497387459006, -0.82735413),\n",
       " (-0.04460507895409999, 0.14922999),\n",
       " (-0.12418460993035305, -0.18718353),\n",
       " (-0.06088223972504998, -0.24619585),\n",
       " (-0.019133964450382127, -0.15437546),\n",
       " (-0.04444663128920387, 0.49814615),\n",
       " (-0.07370871767003978, -0.4577161),\n",
       " (-0.057629158780327906, -0.042347763),\n",
       " (-0.0687678740251617, -0.34174734),\n",
       " (0.0, -0.0052629597),\n",
       " (-0.07238514603145912, 0.087764814),\n",
       " (-0.056519886666063335, -0.11212181),\n",
       " (-0.07414336021230011, -0.1391972),\n",
       " (-0.10877966937926013, 0.14095959),\n",
       " (-0.04043287241625339, -0.08435266),\n",
       " (-0.09996518389254323, -0.27582815),\n",
       " (-0.034077604523075795, -0.010372878),\n",
       " (-0.123443824100957, 0.07820529),\n",
       " (-0.06837670649754574, -0.5177721),\n",
       " (-0.07542819551113226, 0.28570643),\n",
       " (-0.03712466239330401, -0.063331984),\n",
       " (-0.012282474339977196, -0.10703896),\n",
       " (-0.007236693326090878, 0.12226093),\n",
       " (-0.024362859129368905, 0.038653422),\n",
       " (-0.044628920529969564, 0.07953005),\n",
       " (-0.02258964538593331, -0.015044639),\n",
       " (0.0, 0.0041439626),\n",
       " (-0.032660654152929076, 0.0065945834),\n",
       " (0.0, 0.006739674),\n",
       " (-0.03897460474744372, -0.10174602),\n",
       " (0.0, 0.002269435),\n",
       " (-0.00723669332609087, 0.0086806845),\n",
       " (-0.014187969592427824, -0.03312502),\n",
       " (-0.032810136814079904, 0.07888931),\n",
       " (-0.028388291090188887, 0.045912646),\n",
       " (-0.1975379588166275, 0.03558056),\n",
       " (-0.15727012732538248, -0.2522589),\n",
       " (-0.05834590878777794, 0.03962806),\n",
       " (-0.031109103189984683, -0.123344555),\n",
       " (-0.15317020880004906, -0.14849974),\n",
       " (-0.14165791798482888, -0.073568076),\n",
       " (0.0, -0.0019829432),\n",
       " (-0.06081696660070386, -0.21646303),\n",
       " (-0.11245602063416325, -0.021234408),\n",
       " (-0.02875841247440681, -0.090192616),\n",
       " (-0.024764131447848618, -0.15428154),\n",
       " (-0.05426830109781796, -0.117605485),\n",
       " (-0.1407521022627262, 0.6255782),\n",
       " (-0.059618298028002135, -0.20999134),\n",
       " (-0.042243323935662096, 0.30706367),\n",
       " (-0.15417436497939982, 1.5980233),\n",
       " (-0.13203712724459166, -0.19026266),\n",
       " (-0.10927794968604712, 0.17688149),\n",
       " (-0.07645107387980005, 0.07183227),\n",
       " (-0.03202703668767279, -0.13032742),\n",
       " (-0.0593424432849161, -0.08853425),\n",
       " (-0.06887171032491207, 1.1364568),\n",
       " (-0.05012289756187794, -0.09947225),\n",
       " (-0.05865045187594655, -0.033554636),\n",
       " (-0.27968144172566667, -0.6515316),\n",
       " (-0.0125253788256461, 0.07719567),\n",
       " (-0.17345079243326833, 0.7364919),\n",
       " (-0.020144637090535877, -0.27386668),\n",
       " (-0.04247328891348374, 0.09779927),\n",
       " (-0.14930789916570883, -0.093470395),\n",
       " (-0.08381688453545567, -0.21072482),\n",
       " (-0.010186075676514519, 0.17912784),\n",
       " (-0.023293102397476406, 0.05757782),\n",
       " (-0.052366753267027694, 0.06000191),\n",
       " (-0.07662768407906906, 0.56908107),\n",
       " (-0.017592583419876823, -0.013854422),\n",
       " (-0.01742269351032024, -0.16171023),\n",
       " (-0.13914855348522853, 1.3316785),\n",
       " (-0.16401369980216568, 1.4346447),\n",
       " (-0.02700334063071244, 0.4261812),\n",
       " (-0.07704758498736593, -0.10442358),\n",
       " (-0.035220904254605376, -0.095299974),\n",
       " (-0.05498303193489668, -0.099449486),\n",
       " (-0.053783812388331666, -0.16116428),\n",
       " (-0.058569653912475976, 0.029357944),\n",
       " (-0.11917583951335425, 0.032007247),\n",
       " (-0.0072366933260909, -0.014073576),\n",
       " (-0.14727016198726978, 0.07081156),\n",
       " (-0.1390707019954701, -0.11990301),\n",
       " (0.0, -0.00041098287),\n",
       " (-0.01606806141807088, 0.08480528),\n",
       " (-0.040340294665886324, -0.19383676),\n",
       " (-0.010234497840947137, 0.29949254),\n",
       " (-0.052273909970611834, -0.07152694),\n",
       " (-0.01616257625806882, -0.02799378),\n",
       " (-0.029700509231214377, -0.27368328),\n",
       " (-0.04637420238901516, -0.08934872),\n",
       " (-0.0804256049606316, 0.31064713),\n",
       " (-0.07242139822173117, 4.3232417),\n",
       " (-0.03508652539641767, -0.16139388),\n",
       " (-0.049589120574004344, -0.0134527385),\n",
       " (-0.007236693326090957, 0.06837322),\n",
       " (-0.029615912016257594, -0.07736637),\n",
       " (0.0, -0.0077047236),\n",
       " (-0.012083431443885012, -0.023612194),\n",
       " (-0.14317027782791708, -0.3411769),\n",
       " (-0.016036098140456756, -0.01373926),\n",
       " (-0.053438818884792565, -0.2981366),\n",
       " (-0.08428019203740447, 0.31548244),\n",
       " (-0.013921305115332759, -0.10536641),\n",
       " (-0.09051229235483779, -0.1416974),\n",
       " (-0.012122770676633011, -0.029262811),\n",
       " (-0.045223614448534705, -0.16092479),\n",
       " (-0.09154658156220623, 0.18378258),\n",
       " (-0.09351954934854079, -0.05215828),\n",
       " (0.0, 0.0032978784),\n",
       " (-0.06976286140770825, -0.41766155),\n",
       " (-0.04218014806323681, 0.14115018),\n",
       " (0.0, -0.0051842974),\n",
       " (0.0, 0.0069134682),\n",
       " (-0.29860128191188023, -0.6548744),\n",
       " (-0.051288253250498364, 0.101320505),\n",
       " (-0.05679072392718747, -0.04598367),\n",
       " (-0.010207040494363192, 0.017705733),\n",
       " (-0.035829994173598716, 0.09731079),\n",
       " (0.0, 0.005764976),\n",
       " (-0.01611265630758707, 0.075418),\n",
       " (-0.1145466594292175, 0.30870056),\n",
       " (-0.0215727750327256, -0.020082265),\n",
       " (0.0, 0.0019685987),\n",
       " (-0.06009093999886071, 0.32889247),\n",
       " (-0.08739442303192937, 1.1760573),\n",
       " (-0.05861838751205575, 0.71531004),\n",
       " (-0.06644486598792383, -0.042000443),\n",
       " (-0.1052599205142031, -0.3252604),\n",
       " (-0.0641533131125299, 0.46934175),\n",
       " (-0.057289319032272135, -0.078568876),\n",
       " (-0.007236693326090957, -0.10352461),\n",
       " (-0.04517710314667248, -0.013904743),\n",
       " (-0.007236693326090958, 0.33295673),\n",
       " (-0.04053659539011856, -0.194767),\n",
       " (-0.020180754402636624, 0.034935497),\n",
       " (-0.03227123717845248, 0.055150345),\n",
       " (-0.059426316924010285, 4.193064),\n",
       " (-0.03421879801465192, 0.15523122),\n",
       " (-0.007236693326090856, -0.1607031),\n",
       " (-0.05491883932519737, 0.0006225761),\n",
       " (-0.11030746330321238, -0.15989886),\n",
       " (0.0, -0.0027887658),\n",
       " (0.0, 0.0023713605),\n",
       " (-0.057323578942272586, 0.052839775),\n",
       " (0.0, 0.0011223459),\n",
       " (-0.010223453634994172, 0.038537197),\n",
       " (0.0, 0.002878937),\n",
       " (-0.01441210576263065, 0.106240205),\n",
       " (-0.04367899081279829, -0.31107524),\n",
       " (-0.15302543079154846, -0.65862507),\n",
       " (-0.05815956273844792, -0.31213585),\n",
       " (0.0, 0.008118106),\n",
       " (-0.1044950601022801, 1.3354657),\n",
       " (-0.01600393351749738, 0.15312183),\n",
       " (-0.010127409859544327, -0.057489403),\n",
       " (-0.020276575299740196, -0.112261295),\n",
       " (-0.06129113085939104, 1.079303),\n",
       " (-0.07351684145813618, 0.45851254),\n",
       " (-0.08868561808455866, -0.12682502),\n",
       " (-0.045734376780000974, -0.158524),\n",
       " (-0.00992737980175381, -0.119513996),\n",
       " (-0.007236693326090981, 0.07833773),\n",
       " (-0.04458563478675548, -0.00870373),\n",
       " (-0.007236693326090882, -0.05393803),\n",
       " (-0.14046101426454569, 0.2844469),\n",
       " (-0.01568856841904727, -0.1460414),\n",
       " (-0.08939111616548012, -0.38922933),\n",
       " (0.0, -0.00013459101),\n",
       " (0.0, 0.0005564867),\n",
       " (-0.07633155155971681, -0.06561769),\n",
       " (-0.1193196775847839, 0.14840524),\n",
       " (-0.04645845762496292, -0.102892935),\n",
       " (-0.05965070662012794, -0.06255682),\n",
       " (-0.04242384272566192, 0.17792724),\n",
       " (-0.16518032337245195, -0.1662695),\n",
       " (-0.014240161945905437, -0.028188622),\n",
       " (-0.007236693326090909, -0.14127308),\n",
       " (-0.01906493890774839, 0.019144304),\n",
       " (-0.01770121457901147, -0.056559697),\n",
       " (-0.014469731020274004, -0.118670784),\n",
       " (-0.0483212731742601, 0.14400299),\n",
       " (-0.007236693326090937, 0.014537554),\n",
       " (-0.0158132823712322, 0.03360901),\n",
       " (-0.1329011083104794, -0.70667493),\n",
       " (-0.06800567588969406, 1.2873102),\n",
       " (-0.012475328163377038, 0.31109598),\n",
       " (-0.08130083353598065, -0.459854),\n",
       " (-0.12248112213299983, -0.5872945),\n",
       " (0.0, -0.0026145778),\n",
       " (-0.037917682706492845, -0.17242323),\n",
       " (-0.04581000570991379, -0.09761526),\n",
       " (-0.010234482818133167, 0.037623648),\n",
       " (-0.010234037023981518, 0.04233608),\n",
       " (-0.09000199804357577, -0.19374628),\n",
       " (-0.08178985128277019, -0.038654),\n",
       " (0.0, 0.0049492465),\n",
       " (-0.027848030646887106, -0.15258026),\n",
       " (-0.07734586108570007, 0.15070589),\n",
       " (-0.06582587335642524, 0.44380754),\n",
       " (-0.02268780416900271, -0.0564859),\n",
       " (-0.046474998382526465, 0.05799737),\n",
       " (-0.01023437665544558, -0.041065007),\n",
       " (-0.059586441400590294, -0.016796187),\n",
       " (-0.031161062087932987, -0.06231158),\n",
       " (-0.03854469290907424, 0.041446194),\n",
       " (0.0, -0.0036403309),\n",
       " (-0.050703161976269985, 0.027636994),\n",
       " (-0.03923809982002809, 0.174576),\n",
       " (-0.060147915775823624, 0.044384543),\n",
       " (-0.014295721910402868, 0.07300845),\n",
       " (-0.07633682782245682, 0.5139542),\n",
       " (-0.058425949592964745, 0.14731237),\n",
       " (0.0, -0.00663069),\n",
       " (-0.08912571503929298, -0.3343672),\n",
       " (-0.05534121990065138, -0.08764495),\n",
       " (-0.031158504688174406, 0.039510995),\n",
       " (-0.010233741840382254, 0.06112145),\n",
       " (-0.012489200228054278, -0.072655834),\n",
       " (0.0, -0.005546511),\n",
       " (0.0, -0.005724089),\n",
       " (-0.04051939213107203, -0.0011151917),\n",
       " (-0.07106866838400046, 1.204856),\n",
       " (-0.04837826453116181, 0.6019181),\n",
       " (0.0, -0.0005829539),\n",
       " (-0.10126617617231419, 0.30620053),\n",
       " (-0.021568132930724425, -0.10058388),\n",
       " (-0.04304370957622516, -0.08834101),\n",
       " (-0.03450612170522135, -0.009381704),\n",
       " (-0.05978881870899284, 0.42770103),\n",
       " (0.0, 0.0021388996),\n",
       " (-0.0696712166684562, -0.40206504),\n",
       " (-0.04104835122467342, 0.58451515),\n",
       " (-0.007236693326090921, 0.065384224),\n",
       " (-0.03870887064209977, 0.1801475),\n",
       " (-0.03266820702503646, -0.3308431),\n",
       " (-0.019837520710430677, -0.002448433),\n",
       " (-0.02673659180241781, 0.019741707),\n",
       " (0.0, -0.00497103),\n",
       " (-0.017630252240631226, -0.08750235),\n",
       " (-0.024917302827890713, -0.048922405),\n",
       " (-0.0416552029704089, -0.0153983645),\n",
       " (-0.028624383511432205, -0.17207983),\n",
       " (0.0, -0.0017990433),\n",
       " (-0.08805437605895913, 0.038709477),\n",
       " (-0.03637566606549688, 0.20954815),\n",
       " (-0.03638798851079892, 0.19033355),\n",
       " (-0.017635860079058634, -0.16690838),\n",
       " (0.0, 0.0014049625),\n",
       " (-0.09775468913356522, -0.27490693),\n",
       " (-0.010090889186823163, -0.06527942),\n",
       " (0.0, -0.001195573),\n",
       " (-0.03353190071371439, 0.0508304),\n",
       " (-0.007236693326090828, 0.012710642),\n",
       " (-0.030443395835885168, -0.058234602),\n",
       " (-0.10377921747236851, 1.5511615),\n",
       " (-0.03346263270690986, 0.2298846),\n",
       " (-0.02673057646071614, 0.20931277),\n",
       " (-0.13444609597625273, -0.22559959),\n",
       " (-0.014428640850078037, -0.14719914),\n",
       " (0.0, -0.0022267303),\n",
       " (-0.02278526689888637, 0.21920659),\n",
       " (-0.04216203955032308, -0.15921564),\n",
       " (-0.0456484794502658, 0.11825524),\n",
       " (0.0, -0.004514953),\n",
       " (0.0, 0.0009296393),\n",
       " (-0.1446678752817212, -0.24814709),\n",
       " (-0.010199925723519706, 0.023250718),\n",
       " (-0.01897926784410948, -0.055832908),\n",
       " (-0.023924317790130493, -0.22587922),\n",
       " (-0.10844916455690833, 0.025580438),\n",
       " (-0.01251344761370708, -0.033071168),\n",
       " (-0.028778324861072558, -0.032174625),\n",
       " (-0.02888264033659606, -0.09869487),\n",
       " (-0.06925243250156148, 0.13414253),\n",
       " (-0.0190314041844981, 0.06478629),\n",
       " (-0.03946847684571866, 0.52526635),\n",
       " (-0.023956828353958678, 0.16016953),\n",
       " (0.0, 0.0020923617),\n",
       " (0.0, 0.0012383935),\n",
       " (-0.08043682613753948, -0.09035775),\n",
       " (0.0, -0.002014323),\n",
       " (-0.052662569398373646, -0.23507626),\n",
       " (-0.02374761075179349, -0.11077826),\n",
       " (-0.047130159677164704, -0.15220498),\n",
       " (-0.035998865837730605, -0.14640777),\n",
       " (-0.09670426852967715, -0.33464625),\n",
       " (-0.021515421687896868, -0.087215744),\n",
       " (-0.10164246569676663, 0.18157658),\n",
       " (-0.041418749233816846, -0.22962764),\n",
       " (-0.07332876685013422, 4.455952),\n",
       " (-0.0731396633575113, 0.23436818),\n",
       " (-0.08632672716936904, 0.18251581),\n",
       " (-0.04452146533024965, 0.21433699),\n",
       " (-0.010081109923885136, -0.10072824),\n",
       " (-0.06677981531251066, -0.52985877),\n",
       " (15.86513268150523, 0.37972757),\n",
       " (-0.023907070887034705, 0.033296026),\n",
       " (-0.03537045456397911, -0.1554428),\n",
       " (0.0, -0.0051876167),\n",
       " (-0.044205261061488435, -0.07857678),\n",
       " (-0.012488341906769944, 0.19378088),\n",
       " (-0.07693797673097964, 0.08034209),\n",
       " (-0.022487573008271783, -0.12589778),\n",
       " (-0.012528844991512604, -0.015180707),\n",
       " (-0.014317562195258935, 0.20940551),\n",
       " (-0.05143550187268575, -0.18840402),\n",
       " (-0.010019281398638188, -0.16067347),\n",
       " (-0.02819429332875488, -0.0028822422),\n",
       " (-0.01601061651516785, -0.024461599),\n",
       " (-0.039342554906860346, -0.1837829),\n",
       " (0.0, -0.0009082116),\n",
       " (-0.023752204045965203, -0.11094461),\n",
       " (0.0, -0.0020031815),\n",
       " (-0.10525605073951422, -0.0917021),\n",
       " (-0.028756096379322568, 0.075123504),\n",
       " (-0.03053791949635571, -0.06188414),\n",
       " (-0.048551242097581195, -0.23981826),\n",
       " (-0.007236693326090944, 0.23940977),\n",
       " (-0.014081263718922779, 0.03928469),\n",
       " (-0.07560301289157001, 0.56916344),\n",
       " (0.0, 0.0014203927),\n",
       " (-0.021493199289084466, -0.18789122),\n",
       " (-0.041085369473016574, 0.0387024),\n",
       " (-0.01606814634630398, 0.0023343489),\n",
       " (0.0, 0.00019987024),\n",
       " (-0.01441105665309822, -0.045784913),\n",
       " (0.0, -9.538478e-05),\n",
       " (-0.0512339935273829, -0.07205242),\n",
       " (-0.042815551632272596, 0.021700554),\n",
       " (-0.04025626593517632, -0.246046),\n",
       " (-0.01767081707212372, -0.15925801),\n",
       " (0.0, 0.000582451),\n",
       " (-0.060073322131492184, 0.27141997),\n",
       " (-0.007236693326090951, -0.0012586713),\n",
       " (-0.0452252364131848, 0.21720403),\n",
       " (-0.007236693326090901, 0.06617822),\n",
       " (-0.06886314039031342, 0.12397882),\n",
       " (-0.036548469404073705, 0.098369226),\n",
       " (-0.07270004479004637, 0.06455059),\n",
       " (-0.016170708494663105, -0.1577391),\n",
       " (-0.06740324837741507, 0.2284645),\n",
       " (0.0, 0.0013490735),\n",
       " (-0.01016355202586338, 0.0139526725),\n",
       " (-0.01904768133530732, 0.056160156),\n",
       " (-0.09574397031536526, -0.29297236),\n",
       " (-0.007236693326090871, 0.022386413),\n",
       " (0.0, 0.0051273587),\n",
       " (-0.03136134973400292, -0.30665785),\n",
       " (-0.016121428769216982, -0.03471517),\n",
       " (-0.0592376395617386, 0.0437273),\n",
       " (-0.02148398623505598, -0.13427165),\n",
       " (-0.060049580001116265, 0.0938618),\n",
       " (-0.01708313054595251, -0.1050174),\n",
       " (-0.07038196007388878, -0.07518451),\n",
       " (0.0, -0.0017894607),\n",
       " (-0.01855592218855737, -0.29718247),\n",
       " (-0.01243071452986058, 0.057016004),\n",
       " (-0.024991213777370517, 0.19738585),\n",
       " (-0.021544618998004608, 0.010158276),\n",
       " (0.0, -0.0027636332),\n",
       " (-0.05924983832078663, -0.083379656),\n",
       " (-0.016037440073586883, -0.12169923),\n",
       " (-0.044324252919768395, -0.37453038),\n",
       " (-0.007236693326090908, 0.046974335),\n",
       " (-0.06244838257796335, -0.2672403),\n",
       " (0.0, 0.003688519),\n",
       " (-0.009999998448919143, 0.053300135),\n",
       " (-0.04444142852201817, 0.039783694),\n",
       " (-0.03615609980333205, -0.08955047),\n",
       " (0.0, -0.00038778665),\n",
       " (0.0, -0.00038446952),\n",
       " (0.0, -0.0022099593),\n",
       " (-0.017542605450979215, -0.09812823),\n",
       " (-0.10837193894252661, -0.59993076),\n",
       " (-0.018705172452940413, -0.08055829),\n",
       " (-0.026550034691797193, 0.17491905),\n",
       " (-0.030325639074147297, -0.07247181),\n",
       " (0.0, -0.0025735693),\n",
       " (-0.03835516795429334, -0.20384209),\n",
       " (0.0, -0.0003790618),\n",
       " (-0.01020289662557096, 0.113000475),\n",
       " (-0.02457890029215829, -0.07183103),\n",
       " (-0.02600003855354557, 0.054924518),\n",
       " (-0.012457583916403727, -0.02202429),\n",
       " (-0.021316699321808515, 0.08098924),\n",
       " (-0.015945246295928788, -0.084470995),\n",
       " (-0.04973554707943459, 0.094001055),\n",
       " (-0.03535715467298934, -0.38908708),\n",
       " (-0.017404425372072343, -0.24858207),\n",
       " (0.0, -0.0034490526),\n",
       " (-0.039940086405574664, -0.19026703),\n",
       " (-0.0400207683084772, -0.27291155),\n",
       " (-0.03742765413839544, 0.07072103),\n",
       " (-0.07455294223049588, 0.016836317)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of 1 sample for qualitative comparision\n",
    "list(zip(train_dataset.y[:1].flatten(), model.predict(dc.data.NumpyDataset(f.featurize(train_dataset.X[:1]), y[:1])).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d15db",
   "metadata": {},
   "source": [
    "# Dump the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea801db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import dgl\n",
    "\n",
    "class MPNNMolEmbedder(nn.Module):\n",
    "    \"\"\"MPNN embedder.\"\"\"\n",
    "    def __init__(self, gnn, readout):\n",
    "        super(MPNNMolEmbedder, self).__init__()\n",
    "\n",
    "        self.gnn = gnn\n",
    "        self.readout = readout\n",
    "\n",
    "    def _prepare_batch(self, g):\n",
    "        dgl_graphs = [graph.to_dgl_graph() for graph in g]\n",
    "        inputs = dgl.batch(dgl_graphs).to(\"cpu\")\n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, g):\n",
    "        \"\"\"Graph-level regression/soft classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : GraphData\n",
    "            GraphData for a batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        graph embeddings\n",
    "        \"\"\"\n",
    "        dgl_g = self._prepare_batch(g)\n",
    "        node_feats = self.gnn(dgl_g, dgl_g.ndata[\"x\"], dgl_g.edata[\"edge_attr\"])\n",
    "        graph_feats = self.readout(dgl_g, node_feats)\n",
    "        return graph_feats\n",
    "\n",
    "class MPNNAtomEmbedder(nn.Module):\n",
    "    \"\"\"MPNN embedder.\"\"\"\n",
    "    def __init__(self, gnn):\n",
    "        super(MPNNAtomEmbedder, self).__init__()\n",
    "        self.gnn = gnn\n",
    "\n",
    "    def _prepare_batch(self, g):\n",
    "        dgl_graphs = [graph.to_dgl_graph() for graph in g]\n",
    "        inputs = dgl.batch(dgl_graphs).to(\"cpu\")\n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, g, idx):\n",
    "        \"\"\"Graph-level regression/soft classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : GraphData\n",
    "            GraphData for a batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        graph embeddings\n",
    "        \"\"\"\n",
    "        dgl_g = self._prepare_batch(g)\n",
    "        node_feats = self.gnn(dgl_g, dgl_g.ndata[\"x\"], dgl_g.edata[\"edge_attr\"])\n",
    "        return node_feats[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "067176ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_embedder = MPNNMolEmbedder(*list(model.model.model.children())[:2])\n",
    "atom_embedder = MPNNAtomEmbedder(*list(model.model.model.children())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad5c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNNMolEmbedder(\n",
       "  (gnn): MPNNGNN(\n",
       "    (project_node_feats): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gnn_layer): NNConv(\n",
       "      (edge_func): Sequential(\n",
       "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(64, 64)\n",
       "  )\n",
       "  (readout): Set2Set(\n",
       "    n_iters=6\n",
       "    (lstm): LSTM(128, 64, num_layers=3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7dfbcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNNAtomEmbedder(\n",
       "  (gnn): MPNNGNN(\n",
       "    (project_node_feats): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gnn_layer): NNConv(\n",
       "      (edge_func): Sequential(\n",
       "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(64, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc0b3515",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_dgl_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164915/783204037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matom_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/de_nono/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_164915/2192804282.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdgl_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mnode_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgl_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"edge_attr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_164915/2192804282.py\u001b[0m in \u001b[0;36m_prepare_batch\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdgl_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgl_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_164915/2192804282.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdgl_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgl_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_dgl_graph'"
     ]
    }
   ],
   "source": [
    "atom_embedder([f.featurize(train_dataset.X[4])], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55424276",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mol_embedder, \"models/MPNNMolEmbedder.pt\")\n",
    "torch.save(atom_embedder, \"models/MPNNAtomEmbedder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd479f",
   "metadata": {},
   "source": [
    "# Load the model and test on a new molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef27df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2059, -0.0849, -0.1006, -0.0044, -0.1132,  0.0636, -0.0562, -0.0880,\n",
       "          0.0564, -0.1513,  0.6869, -0.0258,  0.1665, -0.0613, -0.0625,  0.0389,\n",
       "          0.1549,  0.2592, -0.0081, -0.1675,  0.0320,  0.2885, -0.4807,  0.2448,\n",
       "          0.1672, -0.1394, -0.2062, -0.1849,  0.3588, -0.0253,  0.2217,  0.0475,\n",
       "         -0.0602, -0.0502,  0.1159,  0.5457,  0.1212,  0.0366, -0.1384, -0.2877,\n",
       "          0.0331,  0.2224,  0.1219,  0.1996, -0.2527, -0.3921,  0.1214,  0.0367,\n",
       "         -0.2402, -0.4625,  0.2983,  0.2036,  0.0237,  0.0604, -0.2049,  0.7599,\n",
       "         -0.1182, -0.0570, -0.5632,  0.3133,  0.1270,  0.0536,  0.1903,  0.4422,\n",
       "         -0.9176, -0.3247, -0.4847, -0.9910, -0.0241,  0.1806,  0.0437, -0.9601,\n",
       "          0.2674,  0.9859,  0.9639, -0.4737, -0.0225, -0.9927, -0.2939, -0.5575,\n",
       "         -0.7356,  0.0216,  0.8634,  0.2863, -0.9869, -0.4371,  0.9459, -0.7089,\n",
       "         -0.5666,  0.9137, -0.1022, -0.3242, -0.9025,  0.6342, -0.4937,  0.6653,\n",
       "         -0.6451, -0.9403, -0.2082, -0.4195,  0.1575, -0.9903,  0.9986,  0.4441,\n",
       "          0.2235,  0.9687, -0.8648, -0.1222,  0.8712,  0.0584, -0.9025,  0.0566,\n",
       "         -0.9362, -0.9875, -0.0954,  0.8848,  0.9980, -0.9934,  0.5944,  0.3263,\n",
       "          0.0108, -0.9988,  0.6034, -0.4589,  0.9901,  0.5968,  0.3258, -0.8748],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([-0.7246, -0.3192, -0.3067, -0.9638, -0.1031,  0.2142,  0.0100, -0.8536,\n",
       "          0.3703,  0.9687,  0.9185, -0.0022, -0.2574, -0.9804, -0.2365, -0.3060,\n",
       "         -0.5417,  0.1997,  0.7316,  0.5097, -0.9631, -0.3713,  0.8697, -0.8795,\n",
       "         -0.5614,  0.7115,  0.0050, -0.6477, -0.8190,  0.6550, -0.3435,  0.9365,\n",
       "         -0.4749, -0.9358, -0.2327, -0.5906,  0.2767, -0.9621,  0.9947,  0.3540,\n",
       "          0.4310,  0.8928, -0.8357, -0.1536,  0.8263,  0.1677, -0.7354,  0.0951,\n",
       "         -0.7423, -0.9465,  0.0697,  0.7014,  0.9914, -0.9725,  0.2568, -0.7252,\n",
       "          0.1484, -0.9951,  0.5186,  0.3719,  0.9585,  0.5059, -0.1065, -0.5941],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import torch\n",
    "\n",
    "# Featurizer\n",
    "f = dc.feat.MolGraphConvFeaturizer(use_edges=True, use_partial_charge=True)\n",
    "\n",
    "# Model\n",
    "mol_em_model = torch.load(\"models/MPNNMolEmbedder.pt\")\n",
    "atom_em_model = torch.load(\"models/MPNNAtomEmbedder.pt\")\n",
    "\n",
    "def mol_to_embedding(mol):\n",
    "    features = f.featurize([mol])[0]\n",
    "    return mol_em_model([features])[0]\n",
    "\n",
    "def atom_to_embedding(mol, idx):\n",
    "    features = f.featurize([mol])[0]\n",
    "    return atom_em_model([features], idx)\n",
    "\n",
    "mol_to_embedding(Chem.MolFromSmiles(\"CCCCCC\")), atom_to_embedding(Chem.MolFromSmiles(\"CCCCCC\"), 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
