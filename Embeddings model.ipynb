{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71214824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 19:45:07.654947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-23 19:45:07.759590: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:45:07.759606: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-23 19:45:07.780663: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-23 19:45:08.282526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:45:08.282596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:45:08.282603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "import torch\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85fe50",
   "metadata": {},
   "source": [
    "# Train a embedding model on ChemBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df91be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.26 ms, sys: 350 Âµs, total: 9.61 ms\n",
      "Wall time: 8.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load raw dataset\n",
    "chembl_tasks, datasets, transformers = dc.molnet.load_chembl(shard_size=2000, featurizer=\"raw\", set=\"5thresh\", splitter=\"random\")\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e7faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 608 ms, total: 2min 54s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Featurize the input\n",
    "f = dc.feat.MolGraphConvFeaturizer(use_edges=True, use_partial_charge=True)\n",
    "x = f.featurize(train_dataset.X)\n",
    "y = train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71520f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train the MPNN model\n",
    "model = dc.models.torch_models.MPNNModel(len(chembl_tasks), number_atom_features=31, number_bond_features=11)\n",
    "\n",
    "print(model.model)\n",
    "\n",
    "model.fit(dc.data.NumpyDataset(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e920cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see some scores (rmse)\n",
    "avg_rms = dc.metrics.Metric(dc.metrics.rms_score, np.mean)\n",
    "model.evaluate(dc.data.NumpyDataset(x, y), [avg_rms], transformers), model.evaluate(dc.data.NumpyDataset(f.featurize(valid_dataset.X), valid_dataset.y), [avg_rms], transformers), model.evaluate(dc.data.NumpyDataset(f.featurize(test_dataset.X), test_dataset.y), [avg_rms], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of 1 sample for qualitative comparision\n",
    "list(zip(train_dataset.y[:1].flatten(), model.predict(dc.data.NumpyDataset(x[:1], y[:1])).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d15db",
   "metadata": {},
   "source": [
    "# Dump the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4120ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea801db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import dgl\n",
    "\n",
    "class MPNNMolEmbedder(nn.Module):\n",
    "    \"\"\"MPNN embedder.\"\"\"\n",
    "    def __init__(self, gnn, readout):\n",
    "        super(MPNNMolEmbedder, self).__init__()\n",
    "\n",
    "        self.gnn = gnn\n",
    "        self.readout = readout\n",
    "\n",
    "    def _prepare_batch(self, g):\n",
    "        dgl_graphs = [graph.to_dgl_graph() for graph in g]\n",
    "        inputs = dgl.batch(dgl_graphs).to(\"cpu\")\n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, g):\n",
    "        \"\"\"Graph-level regression/soft classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : GraphData\n",
    "            GraphData for a batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        graph embeddings\n",
    "        \"\"\"\n",
    "        dgl_g = self._prepare_batch(g)\n",
    "        node_feats = self.gnn(dgl_g, dgl_g.ndata[\"x\"], dgl_g.edata[\"edge_attr\"])\n",
    "        graph_feats = self.readout(dgl_g, node_feats)\n",
    "        return graph_feats\n",
    "\n",
    "class MPNNAtomEmbedder(nn.Module):\n",
    "    \"\"\"MPNN embedder.\"\"\"\n",
    "    def __init__(self, gnn):\n",
    "        super(MPNNAtomEmbedder, self).__init__()\n",
    "        self.gnn = gnn\n",
    "\n",
    "    def _prepare_batch(self, g):\n",
    "        dgl_graphs = [graph.to_dgl_graph() for graph in g]\n",
    "        inputs = dgl.batch(dgl_graphs).to(\"cpu\")\n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, g, idx):\n",
    "        \"\"\"Graph-level regression/soft classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : GraphData\n",
    "            GraphData for a batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        graph embeddings\n",
    "        \"\"\"\n",
    "        dgl_g = self._prepare_batch(g)\n",
    "        node_feats = self.gnn(dgl_g, dgl_g.ndata[\"x\"], dgl_g.edata[\"edge_attr\"])\n",
    "        return node_feats[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "067176ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_embedder = MPNNMolEmbedder(*list(model.model.model.children())[:2])\n",
    "atom_embedder = MPNNAtomEmbedder(*list(model.model.model.children())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ad5c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNNMolEmbedder(\n",
       "  (gnn): MPNNGNN(\n",
       "    (project_node_feats): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gnn_layer): NNConv(\n",
       "      (edge_func): Sequential(\n",
       "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(64, 64)\n",
       "  )\n",
       "  (readout): Set2Set(\n",
       "    n_iters=6\n",
       "    (lstm): LSTM(128, 64, num_layers=3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7dfbcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNNAtomEmbedder(\n",
       "  (gnn): MPNNGNN(\n",
       "    (project_node_feats): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gnn_layer): NNConv(\n",
       "      (edge_func): Sequential(\n",
       "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(64, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc0b3515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_embedder([x[4]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55424276",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mol_embedder, \"models/MPNNMolEmbedder.pt\")\n",
    "torch.save(atom_embedder, \"models/MPNNAtomEmbedder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd479f",
   "metadata": {},
   "source": [
    "# Load the model and test on a new molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef27df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4273, -0.0054,  0.0300, -0.5470,  0.7364,  0.0445,  0.0112, -0.0166,\n",
       "          0.1102,  0.2216,  0.0039,  0.1971, -0.3468, -0.0202, -0.2214,  0.0314,\n",
       "         -0.0983, -0.5491, -0.2083,  0.1508, -0.7335,  0.0810, -0.0330, -0.0227,\n",
       "          0.1960, -0.9099,  0.0609,  0.7126, -0.1994,  0.4139,  0.6269, -0.0964,\n",
       "         -0.4431, -0.3666, -0.2090, -0.0110,  0.3658,  0.1680, -0.5915,  0.0269,\n",
       "          0.0530,  0.1097, -0.0087,  0.3116,  0.0679,  0.1380, -0.0237,  0.4257,\n",
       "          0.2114,  0.1945, -0.2312,  0.0227, -0.0225,  0.0219,  0.6036,  0.0149,\n",
       "         -0.1436, -0.0034,  0.2187, -0.8046, -0.6189, -0.1587,  0.5385, -0.1924,\n",
       "          0.0639,  0.8521, -0.2918,  0.9619,  0.9513,  0.9992,  0.4112,  0.7927,\n",
       "         -0.3629,  0.9802,  0.9209,  0.9591,  0.3266,  0.3460,  0.9029,  0.7934,\n",
       "          0.2595,  0.1027,  0.0793, -0.4858,  0.4777,  0.8709, -0.5346,  0.2575,\n",
       "         -0.1317, -0.6196,  0.0855, -0.0145,  0.3551,  0.9084,  0.3139,  0.1671,\n",
       "          0.8924,  0.2319,  0.9646, -0.1910, -0.9946,  0.5808,  0.9913,  0.7550,\n",
       "          0.9941, -0.6741,  0.7939, -0.6908, -0.7154,  0.4073, -0.8906, -0.0866,\n",
       "         -0.8487,  0.9707,  0.9529,  0.6419,  0.4735, -0.3162, -0.9559,  0.9021,\n",
       "         -0.9854,  0.5881,  0.9253, -0.9551, -0.9820,  0.9989, -0.0131, -0.5751],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([-0.0553,  0.6144, -0.2074,  0.9311,  0.7983,  0.9963,  0.3982,  0.4037,\n",
       "         -0.3591,  0.9264,  0.6560,  0.9131,  0.0583, -0.5277,  0.6510,  0.6255,\n",
       "          0.2520,  0.7575,  0.0651, -0.2793,  0.5243,  0.8168, -0.3708,  0.3999,\n",
       "         -0.3302, -0.2251,  0.0605,  0.4260,  0.3280,  0.7918,  0.0107,  0.3193,\n",
       "          0.8727, -0.0825,  0.9200, -0.3635, -0.9755,  0.3848,  0.9659,  0.6877,\n",
       "          0.9731, -0.1111,  0.8419, -0.4575, -0.2670, -0.0876, -0.7401, -0.0774,\n",
       "         -0.5283,  0.8668,  0.8141,  0.5509,  0.1752, -0.2583, -0.8289,  0.8615,\n",
       "         -0.9335,  0.0932,  0.6824, -0.8799, -0.9296,  0.9952, -0.0569, -0.6201],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import torch\n",
    "\n",
    "# Featurizer\n",
    "f = dc.feat.MolGraphConvFeaturizer(use_edges=True, use_partial_charge=True)\n",
    "\n",
    "# Model\n",
    "mol_em_model = torch.load(\"models/MPNNMolEmbedder.pt\")\n",
    "atom_em_model = torch.load(\"models/MPNNAtomEmbedder.pt\")\n",
    "\n",
    "def mol_to_embedding(mol):\n",
    "    features = f.featurize([mol])[0]\n",
    "    return mol_em_model([features])[0]\n",
    "\n",
    "def atom_to_embedding(mol, idx):\n",
    "    features = f.featurize([mol])[0]\n",
    "    return atom_em_model([features], idx)\n",
    "\n",
    "mol_to_embedding(Chem.MolFromSmiles(\"CCCCCC\")), atom_to_embedding(Chem.MolFromSmiles(\"CCCCCC\"), 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
