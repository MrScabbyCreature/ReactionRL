{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MAIN_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f862867f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "\n",
    "from action_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d77759",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mols = pickle.load(open(\"datasets/my_uspto/unique_start_mols.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660f7320",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10302it [00:26, 395.28it/s]                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10302, 10)\n",
      "(10302, 10)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "main_df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "steps = 1\n",
    "\n",
    "def generate_train_data(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    df = pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    index = []\n",
    "    \n",
    "    # Get sequences\n",
    "    try:\n",
    "        for i in range(steps):\n",
    "            actions = get_applicable_actions(mol)\n",
    "            if actions.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            # Apply a random action\n",
    "            rand_idx = np.random.randint(0, actions.shape[0])\n",
    "            product = apply_action(mol, *actions.iloc[rand_idx])\n",
    "\n",
    "            # Add it to df\n",
    "            df.loc[df.shape[0], :] = [Chem.MolToSmiles(mol)] + actions.iloc[rand_idx].tolist() + [Chem.MolToSmiles(product)]\n",
    "            index.append(actions.iloc[rand_idx].name)\n",
    "\n",
    "            # Next reactant = product\n",
    "            mol = product\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(columns=['reactant', 'rsub', 'rcen', 'rsig', 'rsig_cs_indices', 'psub', 'pcen', 'psig', 'psig_cs_indices', 'product'])\n",
    "    \n",
    "    # Fix index\n",
    "    df.index = index\n",
    "    \n",
    "    # Make combinations for multi-step possibilities of source-->target\n",
    "    for i in range(df.shape[0]-1, 0, -1):\n",
    "        new_df = df.iloc[:i].copy()\n",
    "        new_df[\"product\"] = df.iloc[i][\"product\"]\n",
    "        df = pd.concat([df, new_df])\n",
    "        \n",
    "    return df\n",
    "\n",
    "df_list = []\n",
    "final_shape = 0\n",
    "# Create dataset for 5 step pred\n",
    "with Pool(30) as p, tqdm.tqdm(total=N) as pbar:\n",
    "    while final_shape < N:\n",
    "        smiles = np.random.choice(start_mols, size=(1000,))\n",
    "\n",
    "        for new_df in p.imap_unordered(generate_train_data, smiles, chunksize=10):\n",
    "            df_list.append(new_df)\n",
    "            final_shape += new_df.shape[0]\n",
    "            \n",
    "        pbar.update(final_shape - pbar.n)\n",
    "\n",
    "main_df = pd.concat(df_list)\n",
    "del df_list\n",
    "print(main_df.shape)\n",
    "\n",
    "# randomize\n",
    "main_df = pd.concat([main_df[:int(main_df.shape[0]*0.8)].sample(frac=1), main_df[int(main_df.shape[0]*0.8):].sample(frac=1)])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58b5a",
   "metadata": {},
   "source": [
    "# Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e1a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1e61661530>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3432cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48289f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden=1, hidden_size=50):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(num_hidden):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            \n",
    "        self.last_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        out = self.last_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662cf55",
   "metadata": {},
   "source": [
    "# Helper functions and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835d1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchdrug import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32366ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"models/zinc2m_gin.pth\"\n",
    "gin_model = torch.load(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00cda6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_from_smile(smile):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smile, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "    return mol\n",
    "\n",
    "def get_mol_embedding(model, smiles):\n",
    "    # deepchem - attribute masking\n",
    "    if isinstance(smiles, str):\n",
    "        mol = molecule_from_smile(smiles)\n",
    "    elif isinstance(smiles, list):\n",
    "        mol = list(map(molecule_from_smile, smiles))\n",
    "        mol = data.Molecule.pack(mol)\n",
    "    else:\n",
    "        mol = smiles\n",
    "    mol = mol.to(device)\n",
    "    emb = model(mol, mol.node_feature.float())[\"graph_feature\"]\n",
    "    return emb.detach()\n",
    "\n",
    "def get_atom_embedding(model, smiles, idx):\n",
    "    try:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\")\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    except Exception as e:\n",
    "        mol = data.Molecule.from_smiles(smiles, atom_feature=\"pretrain\", bond_feature=\"pretrain\", with_hydrogen=True)\n",
    "        emb = model(mol, mol.node_feature.float())[\"node_feature\"][idx]\n",
    "    return emb.detach()\n",
    "\n",
    "def get_action_embedding(model, action_df):\n",
    "    rsub, rcen, rsig, _, psub, pcen, psig, __ = [action_df[c] for c in action_df.columns]\n",
    "#     print(get_mol_embedding(model, rsub).shape)\n",
    "#     print(get_atom_embedding(model, rsig, rcen).shape)\n",
    "#     print(get_mol_embedding(model, rsig).shape)\n",
    "#     print(get_mol_embedding(model, psub).shape)\n",
    "#     print(get_atom_embedding(model, psig, pcen).shape)\n",
    "#     print(get_mol_embedding(model, psig).shape)\n",
    "    embedding = torch.concatenate([\n",
    "#                         get_mol_embedding(model, rsub), \n",
    "#                         get_atom_embedding(model, rsig, rcen) / 5, \n",
    "                        get_mol_embedding(model, rsig), \n",
    "#                         get_mol_embedding(model, psub), \n",
    "#                         get_atom_embedding(model, psig, pcen) / 5, \n",
    "                        get_mol_embedding(model, psig)\n",
    "                    ], axis=1)\n",
    "    return embedding\n",
    "\n",
    "def get_action_embedding_from_packed_molecule(model, rsig, psig):\n",
    "    embedding = torch.concatenate([\n",
    "                            get_mol_embedding(model, rsig), \n",
    "                           get_mol_embedding(model, psig)\n",
    "                    ], axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c470490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89384, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ge`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ti`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pb`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Al`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ga`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ru`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Ta`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `As`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cr`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Cd`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/abhor/miniconda3/envs/de_novo/lib/python3.7/site-packages/torchdrug-0.2.0-py3.7.egg/torchdrug/data/feature.py:42: UserWarning: Unknown value `Pt`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    }
   ],
   "source": [
    "action_dataset = pd.read_csv(\"datasets/my_uspto/action_dataset-filtered.csv\", index_col=0)\n",
    "action_dataset = action_dataset.loc[action_dataset[\"action_tested\"] & action_dataset[\"action_works\"]]\n",
    "action_dataset = action_dataset[[\"rsub\", \"rcen\", \"rsig\", \"rbond\", \"psub\", \"pcen\", \"psig\", \"pbond\"]]\n",
    "print(action_dataset.shape)\n",
    "\n",
    "action_rsigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"rsig\"])))\n",
    "action_psigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"psig\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddae391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 44/44 [00:04<00:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89384, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_action_dataset_embeddings(model):\n",
    "    batch_size = 2048\n",
    "    action_embeddings = []\n",
    "    for i in tqdm.tqdm(range(0, action_dataset.shape[0], batch_size)):\n",
    "        batch_rsig = action_rsigs[i:min(i+batch_size, action_dataset.shape[0])].to(device)\n",
    "        batch_psig = action_psigs[i:min(i+batch_size, action_dataset.shape[0])].to(device)\n",
    "        action_embeddings.append(get_action_embedding_from_packed_molecule(model, batch_rsig, batch_psig))\n",
    "#         del batch_rsig, batch_psig\n",
    "    action_embeddings = torch.concatenate(action_embeddings)\n",
    "    return action_embeddings\n",
    "\n",
    "action_embeddings = get_action_dataset_embeddings(gin_model)\n",
    "torch.cuda.empty_cache()\n",
    "print(action_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92e20cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 10302/10302 [00:21<00:00, 488.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "def get_emb_indices_and_correct_idx(row):\n",
    "    if isinstance(row, tuple): # For pandas iterrows\n",
    "        row = row[1]\n",
    "    \n",
    "    # Applicable indices\n",
    "    applicable_actions_df = get_applicable_actions(Chem.MolFromSmiles(row[\"reactant\"]))\n",
    "    if applicable_actions_df.shape[0] == 0:\n",
    "        # If there are no applicable actions detected (rdkit problems)\n",
    "        indices_used_for_data = np.where((action_dataset.index == row.name))[0]\n",
    "        correct_idx = 0\n",
    "    else:\n",
    "        indices_used_for_data = np.where(action_dataset.index.isin(applicable_actions_df.index))[0]\n",
    "        \n",
    "        # Correct index\n",
    "        applicable_actions_df = applicable_actions_df.loc[action_dataset.iloc[indices_used_for_data].index]\n",
    "        correct_idx = (applicable_actions_df.index == row.name).argmax()\n",
    "\n",
    "    \n",
    "    return indices_used_for_data, correct_idx\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, main_df.iterrows()), total=main_df.shape[0]):\n",
    "with Pool(20) as p:\n",
    "    for indices_used_for_data, correct_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, main_df.iterrows(), chunksize=50), total=main_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_indices.append(correct_idx)\n",
    "\n",
    "        assert correct_indices[-1] < len(action_embedding_indices[-1]), f\"WHAT!? {correct_indices[-1]} vs {len(indices_used_for_data)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9107e213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([0., 1., 0.]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [3, 4, 5]])\n",
    "b = torch.Tensor([0, 1, 0])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a56268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=None):\n",
    "    '''\n",
    "    Get the rank of the prediction from the applicable actions.\n",
    "    Returns (rank, [list_of_indices before <rank>])\n",
    "    '''\n",
    "    if distance == \"euclidean\":\n",
    "        dist = ((emb_for_comparison-pred)**2).sum(axis=1)\n",
    "    elif distance == \"cosine\":\n",
    "        dist = 1 - torch.mm(emb_for_comparison, pred.view(-1, 1)).view(-1)/(torch.linalg.norm(emb_for_comparison, axis=1)*torch.linalg.norm(pred))\n",
    "\n",
    "    maxy = max(dist)\n",
    "\n",
    "    list_of_indices = []\n",
    "    for attempt in range(dist.shape[0]):\n",
    "        miny = dist.argmin()\n",
    "#         print(miny, correct_index, dist[correct_index], min(dist), maxy)\n",
    "        if dist[miny] == dist[correct_index]:\n",
    "#             print(i, attempt)\n",
    "            break\n",
    "        else:\n",
    "            list_of_indices.append(miny)\n",
    "            if k is not None and len(list_of_indices) == k:\n",
    "                return list_of_indices\n",
    "            dist[miny] = 100000\n",
    "    \n",
    "    # When the rank(correct_index) < k, then returns <rank, list>. So this extra condition - add some indices after rank(correct_index) to the list\n",
    "    if k is not None:\n",
    "        dist[miny] = 100000\n",
    "        for attempt in range(min(k, emb_for_comparison.shape[0]-1) - len(list_of_indices)):\n",
    "            miny = dist.argmin()\n",
    "            list_of_indices.append(miny)\n",
    "            dist[miny] = 100000\n",
    "        return list_of_indices\n",
    "    return attempt, list_of_indices\n",
    "\n",
    "def get_top_k_indices(pred, emb_for_comparison, correct_index, distance=\"euclidean\", k=1):\n",
    "    return get_ranking(pred, emb_for_comparison, correct_index, distance, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7213fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/mangye16/ReID-Survey\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: pytorch Variable, with shape [m, d]\n",
    "      y: pytorch Variable, with shape [n, d]\n",
    "    Returns:\n",
    "      dist: pytorch Variable, with shape [m, n]\n",
    "    \"\"\"\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n",
    "    dist = xx + yy\n",
    "    dist.addmm_(1, -2, x, y.t())\n",
    "    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "    return dist\n",
    "\n",
    "def cosine_dist(x, y):\n",
    "    xy = x.matmul(y.t())\n",
    "\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.linalg.norm(x, axis=1).expand(n, m).t()\n",
    "    yy = torch.linalg.norm(y, axis=1).expand(m, n)\n",
    "    \n",
    "    return 1 - xy / (xx*yy)\n",
    "\n",
    "\n",
    "def softmax_weights(dist, mask):\n",
    "    max_v = torch.max(dist * mask, dim=1, keepdim=True)[0]\n",
    "    diff = dist - max_v\n",
    "    Z = torch.sum(torch.exp(diff) * mask, dim=1, keepdim=True) + 1e-6 # avoid division by zero\n",
    "    W = torch.exp(diff) * mask / Z\n",
    "    return W\n",
    "\n",
    "class WeightedRegularizedTriplet(object):\n",
    "    def __init__(self, dist=\"euclidean\"):\n",
    "        self.ranking_loss = nn.SoftMarginLoss()\n",
    "        self.dist = dist\n",
    "\n",
    "    def __call__(self, global_feat, labels):\n",
    "        if self.dist==\"euclidean\":\n",
    "            dist_mat = euclidean_dist(global_feat, global_feat)\n",
    "        elif self.dist==\"cosine\":\n",
    "            dist_mat = cosine_dist(global_feat, global_feat) ####### NEEEDS TO BE CHANGED!!!!!!!!!!!\n",
    "\n",
    "        N = dist_mat.size(0)\n",
    "        # shape [N, N]\n",
    "        is_pos = labels.expand(N, N).eq(labels.expand(N, N).t()).float()\n",
    "        is_neg = labels.expand(N, N).ne(labels.expand(N, N).t()).float()\n",
    "\n",
    "        # `dist_ap` means distance(anchor, positive)\n",
    "        # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "        dist_ap = dist_mat * is_pos\n",
    "        dist_an = dist_mat * is_neg\n",
    "\n",
    "        weights_ap = softmax_weights(dist_ap, is_pos)\n",
    "        weights_an = softmax_weights(-dist_an, is_neg)\n",
    "        furthest_positive = torch.sum(dist_ap * weights_ap, dim=1)\n",
    "        closest_negative = torch.sum(dist_an * weights_an, dim=1)\n",
    "\n",
    "        y = furthest_positive.new().resize_as_(furthest_positive).fill_(1)\n",
    "        loss = self.ranking_loss(closest_negative - furthest_positive, y)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ae378842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(main_df.shape[0]*0.8))\n",
    "test_idx = np.arange(int(main_df.shape[0]*0.8), main_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5cf7b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = torch.arange(0, int(main_df.shape[0]*0.8))[:500]\n",
    "test_idx = torch.arange(int(main_df.shape[0]*0.8), main_df.shape[0])[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2132bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 500 500\n",
      "200 200 200 200\n",
      "CPU times: user 29.2 s, sys: 1.79 s, total: 31 s\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "train_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"rsig\"]))).to(device)\n",
    "train_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"psig\"]))).to(device)\n",
    "\n",
    "test_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"reactant\"]))).to(device)\n",
    "test_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"product\"]))).to(device)\n",
    "test_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"rsig\"]))).to(device)\n",
    "test_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"psig\"]))).to(device)\n",
    "\n",
    "print(train_reactants.batch_size, train_products.batch_size, train_rsigs.batch_size, train_psigs.batch_size)\n",
    "print(test_reactants.batch_size, test_products.batch_size, test_rsigs.batch_size, test_psigs.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2011ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.GIN = torch.load(\"models/zinc2m_gin.pth\")\n",
    "        self.actor = NeuralNet(self.GIN.output_dim*2, self.GIN.output_dim*2, num_hidden=3, hidden_size=500)\n",
    "        self.critic = NeuralNet(self.GIN.output_dim*4, 1, num_hidden=2, hidden_size=256)\n",
    "    \n",
    "    def forward(self, reac, prod, rsig, psig, out_type=\"both\"):\n",
    "        '''\n",
    "        If out_type=\"actor\", returns actions\n",
    "        If out_type=\"critic\", returns q_value\n",
    "        If out_type=\"both\", returns [actions, q_value]\n",
    "        '''\n",
    "        reac_out = self.GIN(reac, reac.node_feature.float())[\"graph_feature\"]\n",
    "        prod_out = self.GIN(prod, prod.node_feature.float())[\"graph_feature\"]\n",
    "    \n",
    "        output = []\n",
    "        if out_type in [\"both\", \"actor\"]:\n",
    "            output.append(self.actor(torch.concatenate([reac_out, prod_out], axis=1)))\n",
    "\n",
    "        if out_type in [\"both\", \"critic\"]:\n",
    "            psig_out = self.GIN(psig, psig.node_feature.float())[\"graph_feature\"]\n",
    "            rsig_out = self.GIN(rsig, rsig.node_feature.float())[\"graph_feature\"]\n",
    "            output.append(self.critic(torch.concatenate([reac_out, prod_out, rsig_out, psig_out], axis=1)))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e8060",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# experiment_type = \"test\"\n",
    "experiment_type = \"prod\" #(production)\n",
    "\n",
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-3\n",
    "epochs = 2\n",
    "if experiment_type == \"prod\":\n",
    "    epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "for distance_metric, actor_loss_type, topk, emb_model_update in itertools.product([\"euclidean\"], [\"triplet\", \"mse\"], [10], [1]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(f\"Training for actor loss = {actor_loss_type}\")\n",
    "\n",
    "    # Model inits\n",
    "    model = ActorCritic().to(device)\n",
    "    actor_optimizer = torch.optim.Adam(model.parameters(), lr=actor_lr)  \n",
    "    critic_optimizer = torch.optim.Adam(model.parameters(), lr=critic_lr)  \n",
    "    if actor_loss_type == \"triplet\": \n",
    "        actor_loss_criterion = WeightedRegularizedTriplet()\n",
    "    elif actor_loss_type == \"mse\":\n",
    "        actor_loss_criterion = nn.MSELoss()\n",
    "    critic_loss_criterion = nn.MSELoss()\n",
    "    \n",
    "    # Embeddings init\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "    action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "    \n",
    "    # Some helper inits\n",
    "    best_rank = 10000\n",
    "    best_model = None\n",
    "    metric_dict = {\"rank(cosine)\": [], \"rank(euclidean)\": [], \"rmse\": [], \"cos_dist\": []}\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "            actor_actions, critic_qs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "\n",
    "            # Calc negatives\n",
    "            negative_indices = []\n",
    "            \n",
    "            for _i in range(actor_actions.shape[0]):\n",
    "                act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[train_idx[i+_i]]], correct_indices[train_idx[i+_i]]\n",
    "                curr_out = actor_actions[_i].detach()\n",
    "                dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                sorted_idx = torch.argsort(dist)[:topk] # get topk\n",
    "                sorted_idx = sorted_idx[sorted_idx != correct_index] # Remove if correct index in list\n",
    "                negative_indices.append(sorted_idx)\n",
    "                \n",
    "            # actor update\n",
    "            target_embeddings = get_action_embedding_from_packed_molecule(embedding_model, train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "            if actor_loss_type == \"mse\":\n",
    "                actor_loss = actor_loss_criterion(actor_actions, target_embeddings)\n",
    "            elif actor_loss_type == \"triplet\":\n",
    "                negatives = []\n",
    "                for _indices in negative_indices:\n",
    "                    negatives.append(action_embeddings[_indices])\n",
    "                negatives = torch.concatenate(negatives, axis=0)\n",
    "\n",
    "                # Calc loss\n",
    "                itorchuts = torch.concat([actor_actions, target_embeddings, negatives])\n",
    "                labels = torch.concat([torch.arange(actor_actions.shape[0]), torch.arange(target_embeddings.shape[0]), torch.full((negatives.shape[0],), -1)]).to(device)\n",
    "                actor_loss = actor_loss_criterion(itorchuts, labels)\n",
    "            else:\n",
    "                raise Exception(f\"What is {actor_loss_type}?\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "            # critic update\n",
    "            batch_reactants = data.Molecule.pack(sum([[train_reactants[i+_i]]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], []))\n",
    "            batch_products = data.Molecule.pack(sum([[train_products[i+_i]]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], []))\n",
    "            batch_rsigs = data.Molecule.pack(action_rsigs[sum([[correct_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])])            \n",
    "            batch_psigs = data.Molecule.pack(action_psigs[sum([[correct_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])])            \n",
    "            batch_q_targets = torch.Tensor(sum([[1] + [0] * negative_indices[_i].shape[0] for _i in range(actor_actions.shape[0])], [])).view(-1, 1)\n",
    "            \n",
    "            critic_qs = model(batch_reactants.to(device), batch_products.to(device), batch_rsigs.to(device), batch_psigs.to(device), \"critic\")\n",
    "            critic_loss = critic_loss_criterion(critic_qs, batch_q_targets.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            # Emptry any cache (free GPU memory)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print (f'Epoch {epoch}/{epochs}. Batch {i}/{train_reactants.batch_size - batch_size}. Actor loss = {actor_loss.item():.6f} || critic loss = {critic_loss.item():.6f}')#, end='\\r')\n",
    "\n",
    "        # SWITCH INDENT HERE ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            margin_string = f\"# actor_loss = {actor_loss_type} | emb_model_update = {emb_model_update} | dist_metric = {distance_metric} | topk = {topk} #\"\n",
    "            print(\"#\" * len(margin_string))\n",
    "            print(margin_string)\n",
    "            print(\"#\" * len(margin_string))\n",
    "\n",
    "            # Predictions and action component-wise loss\n",
    "            pred, qs = model(test_reactants, test_products, test_rsigs, test_psigs)\n",
    "            pred, qs = pred.detach(), qs.detach()\n",
    "            true = get_action_embedding_from_packed_molecule(embedding_model, test_rsigs, test_psigs) #get_action_embedding(embedding_model, main_df.iloc[test_idx][main_df.columns[1:-1]])\n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_dist\", \"rank(euclidean)\", \"rank(cosine)\", \"time(epoch_start-now)\"])\n",
    "\n",
    "            # Print Test metrics\n",
    "            metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean().item() )\n",
    "            metric_dict[\"cos_dist\"].append( ((pred*true).sum(axis=1) / torch.linalg.norm(pred, axis=1) / torch.linalg.norm(true, axis=1)).mean().item() )\n",
    "\n",
    "            # Print Test metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_index = action_embeddings[action_embedding_indices[test_idx[i]]], correct_indices[test_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_index, distance=dist)\n",
    "                    l.append(rank)\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                metric_dict[f\"rank({dist})\"].append(np.mean(l))\n",
    "\n",
    "            metric_dict[\"time(epoch_start-now)\"] = [f\"{(time.time()-start_time)/60:.2f}min\"]\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "\n",
    "        # Update embedding model and action_embeddings\n",
    "        if epoch % emb_model_update == 0:\n",
    "            embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "            action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "            action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "\n",
    "        # Update best model\n",
    "        if metric_dict[\"rank(euclidean)\"][-1] < best_rank:\n",
    "            best_rank = metric_dict[\"rank(euclidean)\"][-1]\n",
    "            best_model = type(model)()\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "            print(f\"BEST MODEL UPDATED! BEST RANK = {best_rank}\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"rank\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(f\"actor_loss={actor_loss_type}\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "\n",
    "    # save everything\n",
    "    folder = f\"models/supervised/actor-critic/emb_model_update={emb_model_update}||actor_loss={actor_loss_type}||dist_metric={distance_metric}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "    json.dump({\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"distance_metric\": distance_metric,\n",
    "        \"actor_loss\": actor_loss_type,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_rank\": best_rank\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))\n",
    "    print(\"Saved model at\", folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a0c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
