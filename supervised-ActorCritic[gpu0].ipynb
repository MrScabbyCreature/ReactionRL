{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cfa57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run supervised_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d17013",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d77759",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mols = pickle.load(open(\"datasets/my_uspto/unique_start_mols.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f7320",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████▍                   | 64396/100000 [01:03<00:35, 1005.13it/s]"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "N = 100000\n",
    "steps = 5\n",
    "\n",
    "df_list = []\n",
    "final_shape = 0\n",
    "smiles_per_random_sample = 1000\n",
    "pool_chunk_size = 10\n",
    "\n",
    "# Create dataset for multi-step pred\n",
    "with Pool(30) as p, tqdm.tqdm(total=N) as pbar:\n",
    "    while final_shape < N:\n",
    "        smiles = np.random.choice(start_mols, size=(smiles_per_random_sample,))\n",
    "\n",
    "        for new_df in p.imap_unordered(functools.partial(generate_train_data, steps=steps), smiles, chunksize=10):\n",
    "            df_list.append(new_df)\n",
    "            final_shape += new_df.shape[0]\n",
    "            \n",
    "        pbar.update(final_shape - pbar.n)\n",
    "\n",
    "main_df = pd.concat(df_list)\n",
    "del df_list\n",
    "print(main_df.shape)\n",
    "\n",
    "# randomize\n",
    "main_df = pd.concat([main_df[:int(main_df.shape[0]*0.8)].sample(frac=1), main_df[int(main_df.shape[0]*0.8):].sample(frac=1)])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58b5a",
   "metadata": {},
   "source": [
    "# Load/build stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155171f4",
   "metadata": {},
   "source": [
    "#### Action embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dataset = pd.read_csv(\"datasets/my_uspto/action_dataset-filtered.csv\", index_col=0)\n",
    "action_dataset = action_dataset.loc[action_dataset[\"action_tested\"] & action_dataset[\"action_works\"]]\n",
    "action_dataset = action_dataset[[\"rsub\", \"rcen\", \"rsig\", \"rbond\", \"psub\", \"pcen\", \"psig\", \"pbond\"]]\n",
    "print(action_dataset.shape)\n",
    "\n",
    "action_rsigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"rsig\"])))\n",
    "action_psigs = data.Molecule.pack(list(map(molecule_from_smile, action_dataset[\"psig\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a40c3b",
   "metadata": {},
   "source": [
    "#### Indices (for faster access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e20cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I'm storing as lists, so doing numpy operations for the elements\n",
    "correct_applicable_indices = []\n",
    "correct_action_dataset_indices = []\n",
    "action_embedding_indices = []\n",
    "\n",
    "# for indices_used_for_data, correct_idx in tqdm.tqdm(map(get_emb_indices_and_correct_idx, main_df.iterrows()), total=main_df.shape[0]):\n",
    "with Pool(20) as p:\n",
    "    for indices_used_for_data, correct_app_idx, correct_act_idx in tqdm.tqdm(p.imap(get_emb_indices_and_correct_idx, main_df.iterrows(), chunksize=50), total=main_df.shape[0]):\n",
    "        action_embedding_indices.append(indices_used_for_data)\n",
    "        correct_applicable_indices.append(correct_app_idx)\n",
    "        correct_action_dataset_indices.append(correct_act_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad6291",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae378842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(0, int(main_df.shape[0]*0.8))\n",
    "test_idx = np.arange(int(main_df.shape[0]*0.8), main_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0689a41",
   "metadata": {},
   "source": [
    "train_idx = torch.arange(0, int(main_df.shape[0]*0.8))[:500]\n",
    "test_idx = torch.arange(int(main_df.shape[0]*0.8), main_df.shape[0])[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "train_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"reactant\"]))).to(device)\n",
    "train_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"product\"]))).to(device)\n",
    "train_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"rsig\"]))).to(device)\n",
    "train_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[train_idx][\"psig\"]))).to(device)\n",
    "\n",
    "test_reactants = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"reactant\"]))).to(device)\n",
    "test_products = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"product\"]))).to(device)\n",
    "test_rsigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"rsig\"]))).to(device)\n",
    "test_psigs = data.Molecule.pack(list(map(molecule_from_smile, main_df.iloc[test_idx][\"psig\"]))).to(device)\n",
    "\n",
    "print(train_reactants.batch_size, train_products.batch_size, train_rsigs.batch_size, train_psigs.batch_size)\n",
    "print(test_reactants.batch_size, test_products.batch_size, test_rsigs.batch_size, test_psigs.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec1270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actor_lr = 3e-4\n",
    "critic_lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "for distance_metric, actor_loss_type, topk, emb_model_update in itertools.product([\"euclidean\"], [\"mse\", \"triplet\"], [10], [1]):\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(\"@\"*190)\n",
    "    print(f\"Training for actor loss = {actor_loss_type}\")\n",
    "\n",
    "    # Model inits\n",
    "    model = ActorCritic().to(device)\n",
    "    actor_optimizer = torch.optim.Adam(model.parameters(), lr=actor_lr)  \n",
    "    critic_optimizer = torch.optim.Adam(model.parameters(), lr=critic_lr)  \n",
    "    if actor_loss_type == \"triplet\": \n",
    "        actor_loss_criterion = WeightedRegularizedTriplet()\n",
    "    elif actor_loss_type == \"mse\":\n",
    "        actor_loss_criterion = nn.MSELoss()\n",
    "    critic_loss_criterion = nn.MSELoss()\n",
    "    \n",
    "    # Embeddings init\n",
    "    embedding_model = torch.load(\"models/zinc2m_gin.pth\").to(device)\n",
    "    embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "    action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "    action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "    \n",
    "    # Some helper inits\n",
    "    best_rank = 10000\n",
    "    best_model = None\n",
    "    metric_dict = {\"cos_rank_mean\": [], \"euc_rank_mean\": [], \"cos_rank_std\": [], \"euc_rank_std\": [], \n",
    "                   \"cos_rank_tot\": [], \"euc_rank_tot\": [], \"rmse\": [], \"cos_sim\": [], \"time(epoch_start-now)\": []}\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        for i in range(0, train_reactants.batch_size - batch_size, batch_size):\n",
    "            # Forward pass\n",
    "            actor_actions, critic_qs = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "\n",
    "            # Calc negatives\n",
    "            negative_indices = []\n",
    "            \n",
    "            for _i in range(actor_actions.shape[0]):\n",
    "                correct_action_dataset_index = correct_action_dataset_indices[train_idx[i+_i]]\n",
    "                curr_out = actor_actions[_i].detach()\n",
    "                dist = torch.linalg.norm(action_embeddings - curr_out, axis=1)\n",
    "                sorted_idx = torch.argsort(dist)[:topk] # get topk\n",
    "                sorted_idx = sorted_idx[sorted_idx != correct_action_dataset_index] # Remove if correct index in list\n",
    "                negative_indices.append(sorted_idx)\n",
    "                \n",
    "            # critic update\n",
    "            batch_reactants = train_reactants[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_products = train_products[sum([[i+_i]*(1+negative_indices[_i].shape[0]) for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_rsigs = action_rsigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_psigs = action_psigs[sum([[correct_action_dataset_indices[train_idx[i+_i]]] + negative_indices[_i].tolist() for _i in range(actor_actions.shape[0])], [])]\n",
    "            batch_q_targets = torch.Tensor(sum([[1] + [0] * negative_indices[_i].shape[0] for _i in range(actor_actions.shape[0])], [])).view(-1, 1)\n",
    "\n",
    "            \n",
    "            critic_qs = model(batch_reactants.to(device), batch_products.to(device), batch_rsigs.to(device), batch_psigs.to(device), \"critic\")\n",
    "            critic_loss = critic_loss_criterion(critic_qs, batch_q_targets.to(device))\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            # actor update\n",
    "            actor_actions = model(train_reactants[i:i+batch_size], train_products[i:i+batch_size], train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size], \"actor\")\n",
    "            target_embeddings = get_action_embedding_from_packed_molecule(embedding_model, train_rsigs[i:i+batch_size], train_psigs[i:i+batch_size])\n",
    "            if actor_loss_type == \"mse\":\n",
    "                actor_loss = actor_loss_criterion(actor_actions, target_embeddings)\n",
    "            elif actor_loss_type == \"triplet\":\n",
    "                negatives = []\n",
    "                for _indices in negative_indices:\n",
    "                    negatives.append(action_embeddings[_indices])\n",
    "                negatives = torch.concatenate(negatives, axis=0)\n",
    "\n",
    "                # Calc loss\n",
    "                batch_input = torch.concat([actor_actions, target_embeddings, negatives])\n",
    "                labels = torch.concat([torch.arange(actor_actions.shape[0]), torch.arange(target_embeddings.shape[0]), torch.full((negatives.shape[0],), -1)]).to(device)\n",
    "                actor_loss = actor_loss_criterion(batch_input, labels)\n",
    "            else:\n",
    "                raise Exception(f\"What is {actor_loss_type}?\")\n",
    "            \n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "            \n",
    "            # Emptry any cache (free GPU memory)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print (f'Epoch {epoch}/{epochs}. Batch {i}/{train_reactants.batch_size - batch_size}. Actor loss = {actor_loss.item():.6f} || critic loss = {critic_loss.item():.6f}')#, end='\\r')\n",
    "\n",
    "        # SWITCH INDENT HERE ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print()\n",
    "\n",
    "            margin_string = f\"# actor_loss = {actor_loss_type} | emb_model_update = {emb_model_update} | dist_metric = {distance_metric} | topk = {topk} #\"\n",
    "            print(\"#\" * len(margin_string))\n",
    "            print(margin_string)\n",
    "            print(\"#\" * len(margin_string))\n",
    "\n",
    "            # Predictions and action component-wise loss\n",
    "            pred, qs = model(test_reactants, test_products, test_rsigs, test_psigs)\n",
    "            pred, qs = pred.detach(), qs.detach()\n",
    "            true = get_action_embedding_from_packed_molecule(embedding_model, test_rsigs, test_psigs) #get_action_embedding(embedding_model, main_df.iloc[test_idx][main_df.columns[1:-1]])\n",
    "\n",
    "            metric_df = pd.DataFrame(columns=[\"rmse\", \"cos_sim\", \"euc_rank_mean\", \"euc_rank_std\", \"euc_rank_tot\", \"cos_rank_mean\", \"cos_rank_std\", \"cos_rank_tot\", \"time(epoch_start-now)\"])\n",
    "\n",
    "            # Print Test metrics\n",
    "            metric_dict[\"rmse\"].append( (((pred-true)**2).sum(axis=1)**0.5).mean().item() )\n",
    "            metric_dict[\"cos_sim\"].append( ((pred*true).sum(axis=1) / torch.linalg.norm(pred, axis=1) / torch.linalg.norm(true, axis=1)).mean().item() )\n",
    "\n",
    "            # Print Test metric - Rank\n",
    "            for dist in [\"euclidean\", \"cosine\"]:\n",
    "                rank_list = []\n",
    "                l = []\n",
    "                total = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    pred_for_i = pred[i]\n",
    "                    act_emb_for_i, correct_applicable_index = action_embeddings[action_embedding_indices[test_idx[i]]], correct_applicable_indices[test_idx[i]]\n",
    "\n",
    "                    rank, list_of_indices = get_ranking(pred_for_i, act_emb_for_i, correct_applicable_index, distance=dist)\n",
    "                    l.append(rank.item())\n",
    "                    total.append(act_emb_for_i.shape[0])\n",
    "                rank_list.append(f\"{np.mean(l):.4f}({np.mean(total)}) +- {np.std(l):.4f}\")\n",
    "                metric_dict[f\"{dist[:3]}_rank_mean\"].append(np.mean(l))\n",
    "                metric_dict[f\"{dist[:3]}_rank_std\"].append(np.std(l))\n",
    "                metric_dict[f\"{dist[:3]}_rank_tot\"].append(np.mean(total))\n",
    "\n",
    "            metric_dict[\"time(epoch_start-now)\"].append(f\"{(time.time()-start_time)/60:.2f} min\")\n",
    "            for col in metric_df.columns:\n",
    "                metric_df[col] = [metric_dict[col][-1]]\n",
    "            metric_df.index = [epoch]\n",
    "            print(tabulate(metric_df, headers='keys', tablefmt='fancy_grid'))\n",
    "            print()\n",
    "\n",
    "        # Update embedding model and action_embeddings\n",
    "        if epoch % emb_model_update == 0:\n",
    "            embedding_model.load_state_dict(model.GIN.state_dict())\n",
    "            action_embeddings = get_action_dataset_embeddings(embedding_model)\n",
    "            action_embeddings_norm = torch.linalg.norm(action_embeddings, axis=1)\n",
    "\n",
    "        # Update best model\n",
    "        if metric_dict[\"euc_rank_mean\"][-1] < best_rank:\n",
    "            best_rank = metric_dict[\"euc_rank_mean\"][-1]\n",
    "            best_model = type(model)()\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "            print(f\"BEST MODEL UPDATED! BEST RANK = {best_rank}\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for dist in filter(lambda x: \"mean\" in x, metric_dict.keys()):\n",
    "        plt.plot(metric_dict[dist], label=dist)\n",
    "    plt.title(f\"actor_loss={actor_loss_type}\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"ranking\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "\n",
    "    # save everything\n",
    "    folder = f\"models/supervised/actor-critic/emb_model_update={emb_model_update}||actor_loss={actor_loss_type}||steps={steps}||topk={topk}\"\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    torch.save(model, os.path.join(folder, \"model.pth\"))\n",
    "    pd.DataFrame.from_dict(metric_dict).to_csv(os.path.join(folder, \"metrics.csv\"))\n",
    "    fig.savefig(os.path.join(folder, \"plot.png\"))\n",
    "    json.dump({\n",
    "        \"steps(trajectory length)\": steps,\n",
    "        \"actor_lr\": actor_lr,\n",
    "        \"critic_lr\": critic_lr,\n",
    "        \"epochs\": epochs, \n",
    "        \"batch_size\": batch_size,\n",
    "        \"train_samples\": train_idx.shape,\n",
    "        \"test_samples\": test_idx.shape,\n",
    "        \"distance_metric\": distance_metric,\n",
    "        \"actor_loss\": actor_loss_type,\n",
    "        \"topk\": topk,\n",
    "        \"emb_model_update\": emb_model_update,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_rank\": best_rank\n",
    "    }, open(os.path.join(folder, \"config.txt\"), 'w'))\n",
    "    print(\"Saved model at\", folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88277bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
